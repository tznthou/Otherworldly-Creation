import { createSlice, createAsyncThunk, PayloadAction } from '@reduxjs/toolkit';
import { api } from '../../api';
import type { AIProvider } from '../../api/models';

interface AIState {
  // Legacy single provider state
  isOllamaConnected: boolean;
  isInitializing: boolean;
  error: string | null;
  generating: boolean;
  generationHistory: GenerationResult[];
  currentModel: string | null;
  availableModels: string[];
  modelSizes: Record<string, number>;
  serviceStatus: {
    service: {
      available: boolean;
      version?: string;
      error?: string;
    };
    models: {
      count: number;
      list: string[];
    };
    lastChecked: Date | null;
  } | null;
  modelsInfo: {
    success: boolean;
    models: Array<{
      name: string;
      size: number;
      modified_at: string;
    }>;
    error?: string;
  } | null;
  
  // Multi-provider state
  providers: AIProvider[];
  currentProviderId: string | null;
  defaultProviderId: string | null; // æ–°å¢ï¼šé è¨­æä¾›è€…ID
  autoUseDefault: boolean;          // æ–°å¢ï¼šæ˜¯å¦è‡ªå‹•ä½¿ç”¨é è¨­æä¾›è€…
}

interface GenerationResult {
  id: string;
  prompt: string;
  result: string;
  model: string;
  providerId?: string;
  timestamp: Date;
  params: AIParameters;
  usage?: {
    prompt_tokens?: number;
    completion_tokens?: number;
    total_tokens?: number;
  };
}

interface AIParameters {
  temperature: number;
  topP: number;
  maxTokens: number;
  presencePenalty?: number;
  frequencyPenalty?: number;
}

const initialState: AIState = {
  // Multi-provider support
  providers: [],
  currentProviderId: null,
  defaultProviderId: null,    // é è¨­æä¾›è€…
  autoUseDefault: true,        // è‡ªå‹•ä½¿ç”¨é è¨­æä¾›è€…
  
  // Legacy Ollama support (for backward compatibility)
  isOllamaConnected: false,
  isInitializing: false,
  serviceStatus: null,
  
  // Model management
  availableModels: [],
  modelsInfo: null,
  currentModel: null,
  modelSizes: {},
  
  // Generation state
  generating: false,
  error: null,
  generationHistory: [],
};

// ç•°æ­¥ thunks
export const checkOllamaService = createAsyncThunk(
  'ai/checkOllamaService',
  async (_, { rejectWithValue }) => {
    try {
      console.log('Redux: æª¢æŸ¥ Ollama æœå‹™...');
      console.log('Redux: API å°è±¡:', api);
      console.log('Redux: AI API:', api.ai);
      
      const isConnected = await api.ai.checkOllamaService();
      console.log('Redux: Ollama æœå‹™çµæœ:', isConnected);
      return isConnected;
    } catch (error) {
      console.error('Redux: æª¢æŸ¥ Ollama æœå‹™å¤±æ•—:', error);
      console.error('Redux: éŒ¯èª¤è©³æƒ…:', {
        message: error instanceof Error ? error.message : String(error),
        stack: error instanceof Error ? error.stack : undefined
      });
      return rejectWithValue(false);
    }
  }
);

// å»¶é²åˆå§‹åŒ– AI æœå‹™ï¼ˆèƒŒæ™¯åŸ·è¡Œï¼Œä¸é˜»å¡ UIï¼‰
export const initializeAIServiceLazy = createAsyncThunk(
  'ai/initializeAIServiceLazy',
  async (_, { dispatch }) => {
    try {
      console.log('Redux: é–‹å§‹å»¶é² AI æœå‹™åˆå§‹åŒ–...');
      
      // å…ˆå¿«é€Ÿæª¢æŸ¥ Ollama æœå‹™
      const isConnected = await dispatch(checkOllamaService()).unwrap();
      
      if (isConnected) {
        // å¦‚æœé€£æ¥æˆåŠŸï¼ŒèƒŒæ™¯è¼‰å…¥æ¨¡å‹åˆ—è¡¨
        console.log('Redux: Ollama å·²é€£æ¥ï¼Œè¼‰å…¥æ¨¡å‹åˆ—è¡¨...');
        await dispatch(fetchModelsInfo());
      }
      
      return isConnected;
    } catch (error) {
      console.warn('Redux: å»¶é² AI åˆå§‹åŒ–å¤±æ•—:', error);
      // ä¸è¿”å›éŒ¯èª¤ï¼Œå…è¨±æ‡‰ç”¨ç¨‹å¼ç¹¼çºŒé‹è¡Œ
      return false;
    }
  }
);

export const fetchServiceStatus = createAsyncThunk(
  'ai/fetchServiceStatus',
  async (_, { rejectWithValue }) => {
    try {
      console.log('Redux: ç²å–æœå‹™ç‹€æ…‹...');
      const status = await api.ai.getServiceStatus();
      console.log('Redux: æœå‹™ç‹€æ…‹çµæœ:', status);
      return status;
    } catch (error) {
      console.error('Redux: ç²å–æœå‹™ç‹€æ…‹å¤±æ•—:', error);
      return rejectWithValue(null);
    }
  }
);

export const fetchAvailableModels = createAsyncThunk(
  'ai/fetchAvailableModels',
  async (_, { rejectWithValue }) => {
    try {
      console.log('Redux: ç²å–å¯ç”¨æ¨¡å‹...');
      const models = await api.ai.listModels();
      console.log('Redux: å¯ç”¨æ¨¡å‹çµæœ:', models);
      return models;
    } catch (error) {
      console.error('Redux: ç²å–å¯ç”¨æ¨¡å‹å¤±æ•—:', error);
      return rejectWithValue([]);
    }
  }
);

export const fetchModelsInfo = createAsyncThunk(
  'ai/fetchModelsInfo',
  async (_, { rejectWithValue }) => {
    try {
      console.log('Redux: ç²å–æ¨¡å‹è©³ç´°è³‡è¨Š...');
      const modelsInfo = await api.ai.getModelsInfo();
      console.log('Redux: æ¨¡å‹è©³ç´°è³‡è¨Šçµæœ:', modelsInfo);
      return modelsInfo;
    } catch (error) {
      console.error('Redux: ç²å–æ¨¡å‹è©³ç´°è³‡è¨Šå¤±æ•—:', error);
      return rejectWithValue(null);
    }
  }
);

export const checkModelAvailability = createAsyncThunk(
  'ai/checkModelAvailability',
  async (modelName: string) => {
    const result = await api.ai.checkModelAvailability(modelName);
    return { modelName, ...result };
  }
);

export const generateText = createAsyncThunk(
  'ai/generateText',
  async (params: {
    prompt: string;
    model: string;
    aiParams: AIParameters;
  }) => {
    const result = await api.ai.generateText(
      params.prompt,
      params.model,
      params.aiParams
    );
    
    return {
      id: Date.now().toString(),
      prompt: params.prompt,
      result,
      model: params.model,
      timestamp: new Date(),
      params: params.aiParams,
    };
  }
);
// Multi-provider async thunks
export const fetchAIProviders = createAsyncThunk(
  'ai/fetchAIProviders',
  async (_, { rejectWithValue }) => {
    try {
      console.log('Redux: ç²å– AI æä¾›è€…åˆ—è¡¨...');
      const response = await api.aiProviders.getAll();
      console.log('Redux: AI æä¾›è€…åˆ—è¡¨çµæœ:', response);
      
      if (response.success && response.providers) {
        return response.providers;
      } else {
        throw new Error(response.error || 'ç²å–æä¾›è€…å¤±æ•—');
      }
    } catch (error) {
      console.error('Redux: ç²å– AI æä¾›è€…å¤±æ•—:', error);
      return rejectWithValue([]);
    }
  }
);

export const setActiveProvider = createAsyncThunk(
  'ai/setActiveProvider',
  async (providerId: string, { dispatch: _dispatch, getState: _getState }) => {
    try {
      console.log('Redux: è¨­å®šæ´»èºæä¾›è€…:', providerId);
      
      // æ¸¬è©¦æä¾›è€…é€£æ¥
      const testResult = await api.aiProviders.test(providerId);
      
      if (testResult.success) {
        // ç²å–è©²æä¾›è€…çš„å¯ç”¨æ¨¡å‹
        const models = testResult.models || [];
        return {
          providerId,
          models: models.map((model: unknown) => {
            const modelObj = model as Record<string, unknown>;
            const modelId = modelObj.id || modelObj.name || String(model);
            return typeof modelId === 'string' ? modelId : String(modelId);
          }),
          isConnected: true,
        };
      } else {
        throw new Error(testResult.error || 'æä¾›è€…é€£æ¥å¤±æ•—');
      }
    } catch (error) {
      console.error('Redux: è¨­å®šæ´»èºæä¾›è€…å¤±æ•—:', error);
      return {
        providerId,
        models: [],
        isConnected: false,
        error: error instanceof Error ? error.message : 'é€£æ¥å¤±æ•—',
      };
    }
  }
);

export const generateTextWithProvider = createAsyncThunk(
  'ai/generateTextWithProvider',
  async (params: {
    prompt: string;
    providerId: string;
    model: string;
    projectId: string;
    chapterId: string;
    position?: number;  // æ–°å¢ï¼šä½ç½®åƒæ•¸
    aiParams: AIParameters;
    systemPrompt?: string;
  }) => {
    const result = await api.aiProviders.generateText({
      provider_id: params.providerId,
      model: params.model,
      prompt: params.prompt,
      system_prompt: params.systemPrompt,
      project_id: params.projectId,
      chapter_id: params.chapterId,
      position: params.position,  // ğŸ”¥ æ–°å¢ï¼šå‚³éä½ç½®åƒæ•¸
      temperature: params.aiParams.temperature,
      max_tokens: params.aiParams.maxTokens,
      top_p: params.aiParams.topP,
      presence_penalty: params.aiParams.presencePenalty,
      frequency_penalty: params.aiParams.frequencyPenalty,
    });
    
    return {
      id: Date.now().toString(),
      prompt: params.prompt,
      result: typeof result === 'string' ? result : result.generated_text || '',
      model: params.model,
      providerId: params.providerId,
      timestamp: new Date(),
      params: params.aiParams,
      usage: typeof result === 'object' && result && 'usage' in result ? result.usage as {
        prompt_tokens?: number;
        completion_tokens?: number;
        total_tokens?: number;
      } : undefined,
    };
  }
);;

const aiSlice = createSlice({
  name: 'ai',
  initialState,
  reducers: {
    // Legacy single model reducers
    setCurrentModel: (state, action: PayloadAction<string>) => {
      state.currentModel = action.payload;
    },
    
    // Multi-provider reducers
    setCurrentProvider: (state, action: PayloadAction<string>) => {
      state.currentProviderId = action.payload;
      // Clear current model when switching providers
      state.currentModel = null;
      state.availableModels = [];
    },
    setProviderModels: (state, action: PayloadAction<{providerId: string; models: string[]}>) => {
      const { providerId, models } = action.payload;
      if (state.currentProviderId === providerId) {
        state.availableModels = models;
        // Auto-select first model if none selected
        if (!state.currentModel && models.length > 0) {
          state.currentModel = models[0];
        }
      }
    },
    
    // é è¨­æä¾›è€…ç®¡ç†
    setDefaultProvider: (state, action: PayloadAction<string>) => {
      state.defaultProviderId = action.payload;
      // å¦‚æœé–‹å•Ÿè‡ªå‹•ä½¿ç”¨é è¨­ï¼Œç«‹å³åˆ‡æ›
      if (state.autoUseDefault) {
        state.currentProviderId = action.payload;
        // æ¸…ç©ºæ¨¡å‹åˆ—è¡¨ï¼Œç­‰å¾…é‡æ–°è¼‰å…¥
        state.currentModel = null;
        state.availableModels = [];
      }
    },
    toggleAutoUseDefault: (state) => {
      state.autoUseDefault = !state.autoUseDefault;
      // å¦‚æœé–‹å•Ÿè‡ªå‹•ä½¿ç”¨ä¸”æœ‰é è¨­æä¾›è€…ï¼Œç«‹å³åˆ‡æ›
      if (state.autoUseDefault && state.defaultProviderId) {
        state.currentProviderId = state.defaultProviderId;
        state.currentModel = null;
        state.availableModels = [];
      }
    },
    
    // General reducers
    clearError: (state) => {
      state.error = null;
    },
    clearGenerationHistory: (state) => {
      state.generationHistory = [];
    },
    removeGenerationResult: (state, action: PayloadAction<string>) => {
      state.generationHistory = state.generationHistory.filter(
        result => result.id !== action.payload
      );
    },
  },
  extraReducers: (builder) => {
    builder
      // checkOllamaService
      .addCase(checkOllamaService.fulfilled, (state, action) => {
        state.isOllamaConnected = action.payload;
        if (!action.payload) {
          state.availableModels = [];
          state.currentModel = null;
        }
      })
      .addCase(checkOllamaService.rejected, (state) => {
        state.isOllamaConnected = false;
        state.availableModels = [];
        state.currentModel = null;
      })

      // initializeAIServiceLazy
      .addCase(initializeAIServiceLazy.fulfilled, (state, action) => {
        state.isOllamaConnected = action.payload;
        if (!action.payload) {
          state.availableModels = [];
          state.currentModel = null;
        }
      })
      .addCase(initializeAIServiceLazy.rejected, (state) => {
        // å»¶é²åˆå§‹åŒ–å¤±æ•—ä¸å½±éŸ¿æ‡‰ç”¨ç¨‹å¼é‹è¡Œ
        state.isOllamaConnected = false;
      })

      // fetchServiceStatus
      .addCase(fetchServiceStatus.fulfilled, (state, action) => {
        const payload = action.payload as { 
          service?: { available?: boolean; version?: string; error?: string };
          models?: { count?: number; list?: string[] };
        };
        state.serviceStatus = {
          service: {
            available: payload.service?.available || false,
            version: payload.service?.version,
            error: payload.service?.error
          },
          models: {
            count: payload.models?.count || 0,
            list: payload.models?.list || []
          },
          lastChecked: new Date()
        };
        state.isOllamaConnected = payload.service?.available || false;
        if (!payload.service?.available) {
          state.availableModels = [];
          state.currentModel = null;
        }
      })
      .addCase(fetchServiceStatus.rejected, (state, action) => {
        state.error = action.error.message || 'ç²å–æœå‹™ç‹€æ…‹å¤±æ•—';
        state.isOllamaConnected = false;
      })
      
      // fetchAvailableModels
      .addCase(fetchAvailableModels.fulfilled, (state, action) => {
        state.availableModels = action.payload;
        // å¦‚æœæ²’æœ‰é¸æ“‡æ¨¡å‹ä¸”æœ‰å¯ç”¨æ¨¡å‹ï¼Œé¸æ“‡ç¬¬ä¸€å€‹
        if (!state.currentModel && action.payload.length > 0) {
          state.currentModel = action.payload[0];
        }
      })
      .addCase(fetchAvailableModels.rejected, (state, action) => {
        state.error = action.error.message || 'ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—';
        state.availableModels = [];
      })

      // fetchModelsInfo
      .addCase(fetchModelsInfo.fulfilled, (state, action) => {
        interface ModelInfo { name: string; size: number; modified_at: string; }
        const payload = action.payload as { success?: boolean; models?: ModelInfo[]; error?: string } | ModelInfo[];
        
        if (Array.isArray(payload)) {
          // ç›´æ¥è¿”å›æ¨¡å‹åˆ—è¡¨çš„æƒ…æ³
          state.modelsInfo = {
            success: true,
            models: payload,
            error: undefined
          };
          state.availableModels = payload.map(m => m.name);
          if (!state.currentModel && payload.length > 0) {
            state.currentModel = payload[0].name;
          }
        } else {
          // è¿”å›åŒ…å« success å­—æ®µçš„å°è±¡
          state.modelsInfo = {
            success: payload.success || true,
            models: payload.models || [],
            error: payload.error
          };
          const models = payload.models || [];
          if (models.length > 0) {
            state.availableModels = models.map(m => m.name);
            if (!state.currentModel) {
              state.currentModel = models[0].name;
            }
          } else {
            state.availableModels = [];
          }
        }
      })
      .addCase(fetchModelsInfo.rejected, (state, action) => {
        state.error = action.error.message || 'ç²å–æ¨¡å‹è³‡è¨Šå¤±æ•—';
        state.modelsInfo = null;
      })

      // checkModelAvailability
      .addCase(checkModelAvailability.fulfilled, (state, action) => {
        // å¯ä»¥åœ¨é€™è£¡è™•ç†ç‰¹å®šæ¨¡å‹çš„å¯ç”¨æ€§ç‹€æ…‹
        if (!action.payload.isAvailable && state.currentModel === action.payload.modelName) {
          state.currentModel = null;
        }
      })
      
      // generateText
      .addCase(generateText.pending, (state) => {
        state.generating = true;
        state.error = null;
      })
      .addCase(generateText.fulfilled, (state, action) => {
        state.generating = false;
        state.generationHistory.unshift(action.payload);
        // é™åˆ¶æ­·å²è¨˜éŒ„æ•¸é‡
        if (state.generationHistory.length > 50) {
          state.generationHistory = state.generationHistory.slice(0, 50);
        }
      })
      .addCase(generateText.rejected, (state, action) => {
        state.generating = false;
        state.error = action.error.message || 'AI ç”Ÿæˆå¤±æ•—';
      })

      // Multi-provider reducers
      // fetchAIProviders
      .addCase(fetchAIProviders.fulfilled, (state, action) => {
        state.providers = action.payload;
        
        // è¨­å®šé è¨­æä¾›è€…ï¼ˆç¬¬ä¸€å€‹å•Ÿç”¨çš„æä¾›è€…ï¼‰
        if (!state.defaultProviderId && action.payload.length > 0) {
          const enabledProvider = action.payload.find(p => p.is_enabled);
          if (enabledProvider) {
            state.defaultProviderId = enabledProvider.id;
            // å¦‚æœé–‹å•Ÿè‡ªå‹•ä½¿ç”¨é è¨­ï¼Œä¹Ÿè¨­å®šç‚ºç•¶å‰æä¾›è€…
            if (state.autoUseDefault) {
              state.currentProviderId = enabledProvider.id;
            }
          }
        }
        
        // ç¢ºä¿ç•¶å‰æä¾›è€…æœ‰æ•ˆ
        if (!state.currentProviderId && state.defaultProviderId) {
          state.currentProviderId = state.defaultProviderId;
        }
      })
      .addCase(fetchAIProviders.rejected, (state, action) => {
        state.error = action.error.message || 'ç²å– AI æä¾›è€…å¤±æ•—';
        state.providers = [];
      })

      // setActiveProvider
      .addCase(setActiveProvider.fulfilled, (state, action) => {
        const { providerId, models, isConnected } = action.payload;
        state.currentProviderId = providerId;
        
        if (isConnected && Array.isArray(models)) {
          const modelList = models as string[]; // æ˜ç¢ºé¡å‹è½‰æ›
          state.availableModels = modelList;
          // æ™ºèƒ½æ¨¡å‹é¸æ“‡ï¼šåªåœ¨éœ€è¦æ™‚è‡ªå‹•é¸æ“‡
          if (modelList.length > 0) {
            // å¦‚æœç•¶å‰æ¨¡å‹åœ¨æ–°çš„æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œä¿æŒä¸è®Š
            if (state.currentModel && modelList.includes(state.currentModel)) {
              // ç”¨æˆ¶é¸æ“‡çš„æ¨¡å‹ä»ç„¶å¯ç”¨ï¼Œä¿æŒä¸è®Š
              console.log('Redux: ä¿æŒç”¨æˆ¶é¸æ“‡çš„æ¨¡å‹:', state.currentModel);
            } else {
              // ç•¶å‰æ¨¡å‹ä¸åœ¨æ–°åˆ—è¡¨ä¸­æˆ–æ²’æœ‰é¸æ“‡æ¨¡å‹ï¼Œé¸æ“‡ç¬¬ä¸€å€‹
              console.log('Redux: è‡ªå‹•é¸æ“‡ç¬¬ä¸€å€‹æ¨¡å‹:', modelList[0]);
              state.currentModel = modelList[0];
            }
          }
          state.error = null;
        } else {
          state.availableModels = [];
          state.currentModel = null;
          if ('error' in action.payload) {
            state.error = action.payload.error as string;
          }
        }
      })
      .addCase(setActiveProvider.rejected, (state, action) => {
        state.error = action.error.message || 'è¨­å®šæä¾›è€…å¤±æ•—';
        state.availableModels = [];
        state.currentModel = null;
      })

      // generateTextWithProvider
      .addCase(generateTextWithProvider.pending, (state) => {
        state.generating = true;
        state.error = null;
      })
      .addCase(generateTextWithProvider.fulfilled, (state, action) => {
        state.generating = false;
        state.generationHistory.unshift(action.payload);
        // é™åˆ¶æ­·å²è¨˜éŒ„æ•¸é‡
        if (state.generationHistory.length > 50) {
          state.generationHistory = state.generationHistory.slice(0, 50);
        }
      })
      .addCase(generateTextWithProvider.rejected, (state, action) => {
        state.generating = false;
        state.error = action.error.message || 'AI ç”Ÿæˆå¤±æ•—';
      });
  },
});

export const {
  setCurrentModel,
  setCurrentProvider,
  setProviderModels,
  setDefaultProvider,
  toggleAutoUseDefault,
  clearError,
  clearGenerationHistory,
  removeGenerationResult,
} = aiSlice.actions;

export default aiSlice.reducer;