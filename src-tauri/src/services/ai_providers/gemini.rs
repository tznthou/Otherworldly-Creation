use anyhow::{Result, anyhow};
use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::time::Duration;
use std::collections::HashMap;

use super::r#trait::{
    AIProvider, ProviderConfig, AIGenerationRequest, AIGenerationResponse, 
    AIGenerationParams, AIUsageInfo, ModelInfo, detect_model_characteristics, ResponseFormat
};

#[derive(Debug, Serialize, Deserialize)]
struct GeminiRequest {
    contents: Vec<GeminiContent>,
    #[serde(rename = "generationConfig")]
    generation_config: GeminiGenerationConfig,
    #[serde(rename = "safetySettings")]
    safety_settings: Vec<GeminiSafetySettings>,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiContent {
    role: String,
    parts: Option<Vec<GeminiPart>>,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiPart {
    text: String,
    // ğŸ”¥ æ–°å¢ï¼šæ”¯æŒå…¶ä»–å¯èƒ½çš„å­—æ®µ
    #[serde(flatten)]
    other: std::collections::HashMap<String, serde_json::Value>,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiGenerationConfig {
    temperature: f64,
    #[serde(rename = "topP")]
    top_p: f64,
    #[serde(rename = "maxOutputTokens")]
    max_output_tokens: i32,
    #[serde(rename = "stopSequences", skip_serializing_if = "Option::is_none")]
    stop_sequences: Option<Vec<String>>,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiSafetySettings {
    category: String,
    threshold: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiResponse {
    candidates: Vec<GeminiCandidate>,
    #[serde(rename = "usageMetadata")]
    usage_metadata: Option<GeminiUsageMetadata>,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiCandidate {
    content: GeminiContent,
    #[serde(rename = "finishReason")]
    finish_reason: Option<String>,
    index: i32,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiUsageMetadata {
    #[serde(rename = "promptTokenCount")]
    prompt_token_count: Option<i32>,
    #[serde(rename = "candidatesTokenCount")]
    candidates_token_count: Option<i32>,
    #[serde(rename = "totalTokenCount")]
    total_token_count: Option<i32>,
}

/// Google Gemini API æä¾›è€…
#[allow(dead_code)]
pub struct GeminiProvider {
    name: String,
    api_key: String,
    endpoint: String,
    model: String,
    client: Client,
    timeout: Duration,
    settings: HashMap<String, serde_json::Value>,
}

impl GeminiProvider {
    pub fn new(config: &ProviderConfig) -> Result<Self> {
        let api_key = config.api_key
            .as_ref()
            .ok_or_else(|| anyhow!("Gemini éœ€è¦ API é‡‘é‘°"))?
            .clone();

        let client = Client::builder()
            .timeout(Duration::from_secs(300))
            .build()
            .map_err(|e| anyhow!("å»ºç«‹ HTTP å®¢æˆ¶ç«¯å¤±æ•—: {}", e))?;

        let endpoint = config.endpoint
            .clone()
            .unwrap_or_else(|| "https://generativelanguage.googleapis.com/v1beta".to_string());

        Ok(Self {
            name: config.name.clone(),
            api_key,
            endpoint,
            model: config.model.clone(),
            client,
            timeout: Duration::from_secs(120),
            settings: config.settings.clone(),
        })
    }

    /// ç²å–æ¨¡å‹çš„å®Œæ•´åç¨±ï¼ˆç”¨æ–¼APIèª¿ç”¨ï¼‰
    fn get_full_model_name(&self) -> String {
        if self.model.starts_with("models/") {
            self.model.clone()
        } else {
            format!("models/{}", self.model)
        }
    }

    /// ç™¼é€ POST è«‹æ±‚åˆ° Gemini API
    async fn make_post_request<T>(&self, endpoint: &str, body: &impl Serialize) -> Result<T>
    where
        T: for<'de> Deserialize<'de>,
    {
        let url = format!("{}{}", self.endpoint, endpoint);
        let response = self.client
            .post(&url)
            .header("Content-Type", "application/json")
            .header("x-goog-api-key", &self.api_key)
            .json(body)
            .timeout(self.timeout)
            .send()
            .await?;

        if response.status().is_success() {
            let response_text = response.text().await?;
            log::info!("[GeminiProvider] âœ… API å›æ‡‰æˆåŠŸï¼Œé•·åº¦: {} å­—ç¬¦", response_text.len());
            log::info!("[GeminiProvider] ğŸ” å›æ‡‰å…§å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {}", 
                     response_text.chars().take(500).collect::<String>());
            
            let data: T = serde_json::from_str(&response_text)
                .map_err(|e| anyhow!("ğŸš« JSON è§£æéŒ¯èª¤: {}
ğŸ“„ å®Œæ•´å›æ‡‰å…§å®¹: {}", e, response_text))?;
            Ok(data)
        } else {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_default();
            log::error!("[GeminiProvider] âŒ API éŒ¯èª¤ {}: {}", status, error_text);
            
            // ğŸ”¥ æ™ºèƒ½éŒ¯èª¤è™•ç†ï¼šé‡å° 429 éŒ¯èª¤è§£æé‡è©¦ä¿¡æ¯
            if status.as_u16() == 429 {
                let user_friendly_error = Self::parse_rate_limit_error(&error_text);
                Err(anyhow!("{}", user_friendly_error))
            } else {
                Err(anyhow!("ğŸš« Gemini API éŒ¯èª¤ {} ({}): {}", status.as_u16(), status.canonical_reason().unwrap_or("Unknown"), error_text))
            }
        }
    }

    /// ğŸ”¥ è§£æ 429 é€Ÿç‡é™åˆ¶éŒ¯èª¤ï¼Œæä¾›ç”¨æˆ¶å‹å¥½çš„æç¤º
    fn parse_rate_limit_error(error_text: &str) -> String {
        // å˜—è©¦è§£æ JSON éŒ¯èª¤éŸ¿æ‡‰
        if let Ok(json_value) = serde_json::from_str::<serde_json::Value>(error_text) {
            if let Some(error_obj) = json_value.get("error") {
                let mut retry_delay = None;
                let mut quota_type = "æœªçŸ¥é™åˆ¶".to_string();
                
                // è§£æ retryDelay
                if let Some(details) = error_obj.get("details").and_then(|d| d.as_array()) {
                    for detail in details {
                        if let Some(_retry_info) = detail.get("@type")
                            .and_then(|t| t.as_str())
                            .filter(|&t| t.contains("RetryInfo")) {
                            if let Some(delay) = detail.get("retryDelay").and_then(|d| d.as_str()) {
                                retry_delay = Some(delay.to_string());
                            }
                        }
                        
                        // è§£æé…é¡é¡å‹
                        if let Some(violations) = detail.get("violations").and_then(|v| v.as_array()) {
                            for violation in violations {
                                if let Some(quota_metric) = violation.get("quotaMetric").and_then(|q| q.as_str()) {
                                    quota_type = match quota_metric {
                                        s if s.contains("requests") && s.contains("minute") => "æ¯åˆ†é˜è«‹æ±‚æ•¸".to_string(),
                                        s if s.contains("requests") && s.contains("day") => "æ¯æ—¥è«‹æ±‚æ•¸".to_string(),
                                        s if s.contains("input_token") => "æ¯åˆ†é˜è¼¸å…¥ Token æ•¸".to_string(),
                                        _ => "API é…é¡".to_string(),
                                    };
                                    break;
                                }
                            }
                        }
                    }
                }
                
                // ç”Ÿæˆç”¨æˆ¶å‹å¥½çš„éŒ¯èª¤æ¶ˆæ¯
                let base_message = format!("ğŸš« Gemini å…è²»ç‰ˆ API é…é¡å·²é”ä¸Šé™\nğŸ’¡ é™åˆ¶é¡å‹ï¼š{}", quota_type);
                
                if let Some(delay) = retry_delay {
                    format!("{}\nâ° å»ºè­°ç­‰å¾…æ™‚é–“ï¼š{}\n\nğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\nâ€¢ ç­‰å¾…é…é¡é‡ç½®å¾Œå†è©¦\nâ€¢ ä½¿ç”¨ä»˜è²»ç‰ˆ OpenRouter (google/gemini-2.5-flash)\nâ€¢ æˆ–åˆ‡æ›åˆ°å…¶ä»– AI æä¾›è€…", base_message, delay)
                } else {
                    format!("{}\n\nğŸ”§ è§£æ±ºæ–¹æ¡ˆï¼š\nâ€¢ ç¨å¾Œå†è©¦ï¼ˆé€šå¸¸ 1-5 åˆ†é˜å¾Œé‡ç½®ï¼‰\nâ€¢ ä½¿ç”¨ä»˜è²»ç‰ˆ OpenRouter (google/gemini-2.5-flash)\nâ€¢ æˆ–åˆ‡æ›åˆ°å…¶ä»– AI æä¾›è€…", base_message)
                }
            } else {
                "ğŸš« Gemini API é…é¡å·²é”ä¸Šé™ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–åˆ‡æ›åˆ°ä»˜è²»ç‰ˆæœ¬".to_string()
            }
        } else {
            "ğŸš« Gemini API é…é¡å·²é”ä¸Šé™ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–åˆ‡æ›åˆ°ä»˜è²»ç‰ˆæœ¬".to_string()
        }
    }

    /// ç²å–é å®šç¾©çš„ Gemini æ¨¡å‹åˆ—è¡¨
    fn get_available_models() -> Vec<ModelInfo> {
        vec![
            ModelInfo {
                id: "gemini-2.5-pro".to_string(),
                name: "Gemini 2.5 Pro".to_string(),
                description: Some("Google æœ€å¼·å¤§çš„æ€è€ƒæ¨¡å‹ï¼Œå…·å‚™è¤‡é›œæ¨ç†èƒ½åŠ›".to_string()),
                max_tokens: Some(8192), // 8K output tokens
                supports_streaming: true,
                cost_per_token: Some(0.000001), // æ›´æ–°çš„å®šåƒ¹
            },
            ModelInfo {
                id: "gemini-2.5-flash".to_string(),
                name: "Gemini 2.5 Flash".to_string(),
                description: Some("æœ€æ–°çš„å¤šæ¨¡æ…‹æ¨¡å‹ï¼Œå…·å‚™ä¸‹ä¸€ä»£èƒ½åŠ›å’Œå¢å¼·åŠŸèƒ½".to_string()),
                max_tokens: Some(8192),
                supports_streaming: true,
                cost_per_token: Some(0.0000005),
            },
            ModelInfo {
                id: "gemini-2.5-flash-lite".to_string(),
                name: "Gemini 2.5 Flash-Lite".to_string(),
                description: Some("æœ€å¿«é€Ÿä¸”æœ€ç¶“æ¿Ÿçš„å¤šæ¨¡æ…‹æ¨¡å‹ï¼Œé©åˆé«˜é »ä»»å‹™".to_string()),
                max_tokens: Some(8192),
                supports_streaming: true,
                cost_per_token: Some(0.00000025),
            },
            // ä¿ç•™èˆŠç‰ˆæœ¬ä»¥ç¢ºä¿å‘å¾Œå…¼å®¹
            ModelInfo {
                id: "gemini-1.5-pro".to_string(),
                name: "Gemini 1.5 Pro (èˆŠç‰ˆ)".to_string(),
                description: Some("å…ˆå‰ç‰ˆæœ¬çš„å¤šæ¨¡æ…‹æ¨¡å‹".to_string()),
                max_tokens: Some(1048576),
                supports_streaming: true,
                cost_per_token: Some(0.0000035),
            },
            ModelInfo {
                id: "gemini-pro".to_string(),
                name: "Gemini Pro (èˆŠç‰ˆ)".to_string(),
                description: Some("å‚³çµ±ç‰ˆæœ¬çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹".to_string()),
                max_tokens: Some(30720),
                supports_streaming: true,
                cost_per_token: Some(0.0000005),
            },
        ]
    }

    /// ç²å–é è¨­çš„å®‰å…¨è¨­å®š
    fn get_default_safety_settings() -> Vec<GeminiSafetySettings> {
        vec![
            GeminiSafetySettings {
                category: "HARM_CATEGORY_HARASSMENT".to_string(),
                threshold: "BLOCK_MEDIUM_AND_ABOVE".to_string(),
            },
            GeminiSafetySettings {
                category: "HARM_CATEGORY_HATE_SPEECH".to_string(),
                threshold: "BLOCK_MEDIUM_AND_ABOVE".to_string(),
            },
            GeminiSafetySettings {
                category: "HARM_CATEGORY_SEXUALLY_EXPLICIT".to_string(),
                threshold: "BLOCK_MEDIUM_AND_ABOVE".to_string(),
            },
            GeminiSafetySettings {
                category: "HARM_CATEGORY_DANGEROUS_CONTENT".to_string(),
                threshold: "BLOCK_MEDIUM_AND_ABOVE".to_string(),
            },
        ]
    }
}

#[async_trait]
impl AIProvider for GeminiProvider {
    fn name(&self) -> &str {
        &self.name
    }
    
    fn provider_type(&self) -> &str {
        "gemini"
    }

    async fn check_availability(&self) -> Result<bool> {
        log::info!("[GeminiProvider] æª¢æŸ¥ Gemini API å¯ç”¨æ€§...");
        
        // ç™¼é€ç°¡å–®çš„æ¸¬è©¦è«‹æ±‚
        let test_request = GeminiRequest {
            contents: vec![
                GeminiContent {
                    role: "user".to_string(),
                    parts: Some(vec![
                        GeminiPart {
                            text: "Hello".to_string(),
                            other: std::collections::HashMap::new(),
                        }
                    ]),
                }
            ],
            generation_config: GeminiGenerationConfig {
                temperature: 0.1,
                top_p: 0.1,
                max_output_tokens: 50,
                stop_sequences: None,
            },
            safety_settings: Self::get_default_safety_settings(),
        };

        let model_name = self.get_full_model_name();
        let endpoint = format!("/{}:generateContent", model_name);
        
        match self.make_post_request::<GeminiResponse>(&endpoint, &test_request).await {
            Ok(_) => {
                log::info!("[GeminiProvider] Gemini API å¯ç”¨");
                Ok(true)
            }
            Err(e) => {
                log::warn!("[GeminiProvider] Gemini API ä¸å¯ç”¨: {}", e);
                Err(e)
            }
        }
    }

    async fn get_models(&self) -> Result<Vec<ModelInfo>> {
        log::info!("[GeminiProvider] ç²å– Gemini æ¨¡å‹åˆ—è¡¨...");
        
        // Gemini API æ²’æœ‰å…¬é–‹çš„æ¨¡å‹åˆ—è¡¨ç«¯é»ï¼Œè¿”å›é å®šç¾©åˆ—è¡¨
        Ok(Self::get_available_models())
    }

    async fn generate_text(&self, request: AIGenerationRequest) -> Result<AIGenerationResponse> {
        log::info!("[GeminiProvider] é–‹å§‹ç”Ÿæˆæ–‡æœ¬ï¼Œæ¨¡å‹: {}", request.model);
        
        // ğŸ” æª¢æŸ¥ä¸¦æ¨è–¦æ­£ç¢ºçš„æ¨¡å‹åç¨±
        let recommended_models = vec![
            "gemini-1.5-pro", "gemini-1.5-flash", "gemini-pro", 
            "gemini-1.5-pro-latest", "gemini-1.5-flash-latest"
        ];
        
        if !recommended_models.iter().any(|&m| request.model.contains(m)) {
            log::warn!("[GeminiProvider] âš ï¸  æ¨¡å‹åç¨±å¯èƒ½ä¸æ­£ç¢º: '{}'", request.model);
            log::warn!("[GeminiProvider] ğŸ’¡ å»ºè­°ä½¿ç”¨: {:?}", recommended_models);
            
            // å˜—è©¦è‡ªå‹•ä¿®æ­£å¸¸è¦‹éŒ¯èª¤
            let corrected_model = if request.model.contains("2.5") {
                if request.model.contains("pro") {
                    "gemini-1.5-pro-latest".to_string()
                } else {
                    "gemini-1.5-flash-latest".to_string()
                }
            } else {
                request.model.clone()
            };
            
            if corrected_model != request.model {
                log::info!("[GeminiProvider] ğŸ”§ è‡ªå‹•ä¿®æ­£æ¨¡å‹åç¨±: {} -> {}", request.model, corrected_model);
            }
        }

        // æ§‹å»ºå…§å®¹åˆ—è¡¨
        let mut contents = Vec::new();
        
        // Gemini ä¸æ”¯æ´ç³»çµ±è§’è‰²ï¼Œå°‡ç³»çµ±æç¤ºåˆä½µåˆ°ç”¨æˆ¶æ¶ˆæ¯ä¸­
        let user_content = if let Some(system_prompt) = &request.system_prompt {
            format!("{}\n\n{}", system_prompt, request.prompt)
        } else {
            request.prompt.clone()
        };
        
        contents.push(GeminiContent {
            role: "user".to_string(),
            parts: Some(vec![
                GeminiPart {
                    text: user_content,
                    other: std::collections::HashMap::new(),
                }
            ]),
        });

        let gemini_request = GeminiRequest {
            contents,
            generation_config: GeminiGenerationConfig {
                temperature: request.params.temperature,
                top_p: request.params.top_p.unwrap_or(0.95),
                max_output_tokens: request.params.max_tokens,
                stop_sequences: request.params.stop,
            },
            safety_settings: Self::get_default_safety_settings(),
        };

        let model_name = if request.model.starts_with("models/") {
            request.model.clone()
        } else {
            format!("models/{}", request.model)
        };
        
        let endpoint = format!("/{}:generateContent", model_name);
        let response = self.make_post_request::<GeminiResponse>(&endpoint, &gemini_request).await?;
        
        // ğŸ”¥ ä½¿ç”¨éšæ®µä¸€æª¢æ¸¬é‚è¼¯è™•ç†éŸ¿æ‡‰æ ¼å¼å·®ç•°
        let model_chars = detect_model_characteristics(&request.model);
        log::info!("[GeminiProvider] ğŸ” æ¨¡å‹æª¢æ¸¬çµæœ: {:?} -> {:?}", request.model, model_chars.response_format);
        log::info!("[GeminiProvider] ğŸ” API éŸ¿æ‡‰çµæ§‹: candidates æ•¸é‡={}", response.candidates.len());
        
        let actual_text = match model_chars.response_format {
            ResponseFormat::CandidatesArray => {
                // Gemini æ¨™æº–æ ¼å¼ï¼šcandidates é™£åˆ—
                if let Some(candidate) = response.candidates.first() {
                    log::info!("[GeminiProvider] ğŸ” æ‰¾åˆ°ç¬¬ä¸€å€‹ candidateï¼Œindex={}", candidate.index);
                    log::info!("[GeminiProvider] ğŸ” finish_reason={:?}", candidate.finish_reason);
                    
                    // ğŸ”¥ è™•ç† Gemini API çš„ä¸åŒå›æ‡‰æ ¼å¼
                    let content_text = if let Some(parts) = &candidate.content.parts {
                        if !parts.is_empty() {
                            log::info!("[GeminiProvider] ğŸ” content.parts å­˜åœ¨ï¼Œparts æ•¸é‡={}", parts.len());
                            if let Some(part) = parts.first() {
                                log::info!("[GeminiProvider] ğŸ” ç¬¬ä¸€å€‹ part æ–‡æœ¬é•·åº¦: {} å­—ç¬¦", part.text.len());
                                if !part.text.trim().is_empty() {
                                    log::info!("[GeminiProvider] âœ… ä½¿ç”¨æ¨™æº– parts æ ¼å¼");
                                    part.text.clone()
                                } else {
                                    log::warn!("[GeminiProvider] âš ï¸ part.text ç‚ºç©º");
                                    String::new()
                                }
                            } else {
                                log::warn!("[GeminiProvider] âš ï¸ parts é™£åˆ—ç‚ºç©º");
                                String::new()
                            }
                        } else {
                            log::warn!("[GeminiProvider] âš ï¸ parts é™£åˆ—é•·åº¦ç‚º 0");
                            String::new()
                        }
                    } else {
                        // ç•¶ parts ç‚º None æ™‚ï¼Œé€™é€šå¸¸ç™¼ç”Ÿåœ¨ï¼š
                        // 1. MAX_TOKENS - é”åˆ°è¼¸å‡ºé™åˆ¶
                        // 2. SAFETY - å®‰å…¨éæ¿¾å™¨é˜»æ­¢è¼¸å‡º
                        // 3. OTHER - å…¶ä»– API é™åˆ¶
                        log::warn!("[GeminiProvider] âš ï¸ content.parts ç‚º Noneï¼Œfinish_reason={:?}", 
                                 candidate.finish_reason);
                        
                        match candidate.finish_reason.as_deref() {
                            Some("MAX_TOKENS") => {
                                log::warn!("[GeminiProvider] ğŸ’¡ å»ºè­°ï¼šå¢åŠ  max_output_tokens åƒæ•¸æˆ–ä½¿ç”¨æ›´é•·è¼¸å‡ºé™åˆ¶çš„æ¨¡å‹");
                            },
                            Some("SAFETY") => {
                                log::warn!("[GeminiProvider] ğŸ’¡ å…§å®¹è¢«å®‰å…¨éæ¿¾å™¨é˜»æ­¢ï¼Œè«‹èª¿æ•´æç¤ºè©");
                            },
                            Some("STOP") => {
                                log::info!("[GeminiProvider] ğŸ’¡ æ­£å¸¸å®Œæˆï¼Œä½†ç„¡å…§å®¹è¼¸å‡º");
                            },
                            _ => {
                                log::warn!("[GeminiProvider] ğŸ’¡ æœªçŸ¥å®ŒæˆåŸå› ");
                            }
                        }
                        String::new()
                    };
                    
                    content_text
                } else {
                    log::warn!("[GeminiProvider] âš ï¸ candidates é™£åˆ—ç‚ºç©º");
                    String::new()
                }
            },
            _ => {
                // é™ç´šè™•ç†ï¼šå˜—è©¦å¾ candidates ç²å–
                if let Some(candidate) = response.candidates.first() {
                    if let Some(parts) = &candidate.content.parts {
                        if let Some(part) = parts.first() {
                            log::info!("[GeminiProvider] ğŸ“ é™ç´šä½¿ç”¨ candidates é™£åˆ—æ ¼å¼");
                            part.text.clone()
                        } else {
                            log::warn!("[GeminiProvider] âš ï¸ ç„¡æ³•å¾ parts ç²å–å…§å®¹");
                            String::new()
                        }
                    } else {
                        log::warn!("[GeminiProvider] âš ï¸ content.parts ä¸å­˜åœ¨");
                        String::new()
                    }
                } else {
                    log::warn!("[GeminiProvider] âš ï¸ ç„¡æ³•ç²å–ä»»ä½•éŸ¿æ‡‰å…§å®¹");
                    String::new()
                }
            }
        };
        
        if !actual_text.trim().is_empty() {
            log::info!("[GeminiProvider] æ–‡æœ¬ç”ŸæˆæˆåŠŸï¼Œé•·åº¦: {} å­—ç¬¦", actual_text.len());
            
            let usage = response.usage_metadata.map(|usage| {
                AIUsageInfo {
                    prompt_tokens: usage.prompt_token_count,
                    completion_tokens: usage.candidates_token_count,
                    total_tokens: usage.total_token_count,
                }
            });

            Ok(AIGenerationResponse {
                text: actual_text,
                model: request.model,
                usage,
                finish_reason: response.candidates.first()
                    .and_then(|c| c.finish_reason.clone()),
            })
        } else {
            // é‡å°ä¸åŒçš„å¤±æ•—åŸå› æä¾›å…·é«”çš„éŒ¯èª¤æ¶ˆæ¯
            let finish_reason = response.candidates.first()
                .and_then(|c| c.finish_reason.as_ref());
            
            let error_message = match finish_reason {
                Some(reason) if reason == "MAX_TOKENS" => {
                    format!("ğŸš« Gemini è¼¸å‡ºé”åˆ° token é™åˆ¶
ğŸ’¡ å»ºè­°è§£æ±ºæ–¹æ¡ˆï¼š
- ç•¶å‰ max_tokens: {}
- å˜—è©¦å¢åŠ  max_tokens è¨­ç½®
- æˆ–ä½¿ç”¨æ”¯æŒæ›´é•·è¼¸å‡ºçš„æ¨¡å‹ (å¦‚ gemini-1.5-pro)", request.params.max_tokens)
                },
                Some(reason) if reason == "SAFETY" => {
                    "ğŸš« å…§å®¹è¢« Gemini å®‰å…¨éæ¿¾å™¨é˜»æ­¢
ğŸ’¡ å»ºè­°èª¿æ•´æç¤ºè©å…§å®¹ï¼Œé¿å…æ•æ„Ÿè©±é¡Œ".to_string()
                },
                Some(reason) if reason == "RECITATION" => {
                    "ğŸš« å…§å®¹æ¶‰åŠç‰ˆæ¬Šææ–™è¢«éæ¿¾
ğŸ’¡ å»ºè­°ä½¿ç”¨æ›´åŸå‰µçš„æç¤ºè©".to_string()
                },
                Some(reason) => {
                    format!("ğŸš« Gemini ç”Ÿæˆè¢«åœæ­¢ï¼š{}
ğŸ’¡ è«‹æª¢æŸ¥æç¤ºè©å…§å®¹", reason)
                },
                None => {
                    format!("ğŸš« Gemini éŸ¿æ‡‰è§£æå¤±æ•—ï¼šç„¡æ³•ç²å–æ–‡æœ¬å…§å®¹
ğŸ“Š API å›æ‡‰æ­£å¸¸ä½†å…§å®¹ç‚ºç©º
ğŸ” å€™é¸æ•¸é‡: {}, æ¨¡å‹: {}",
                    response.candidates.len(), request.model)
                }
            };
            
            log::error!("[GeminiProvider] {}", error_message);
            Err(anyhow!("{}", error_message))
        }
    }

    async fn validate_api_key(&self, api_key: &str) -> Result<bool> {
        log::info!("[GeminiProvider] é©—è­‰ API é‡‘é‘°...");
        
        // å»ºç«‹è‡¨æ™‚è«‹æ±‚ä¾†æ¸¬è©¦ API é‡‘é‘°
        let temp_client = Client::new();
        let url = format!("{}/models/gemini-2.5-flash:generateContent", self.endpoint);
        
        let test_request = GeminiRequest {
            contents: vec![
                GeminiContent {
                    role: "user".to_string(),
                    parts: Some(vec![
                        GeminiPart {
                            text: "test".to_string(),
                            other: std::collections::HashMap::new(),
                        }
                    ]),
                }
            ],
            generation_config: GeminiGenerationConfig {
                temperature: 0.1,
                top_p: 0.1,
                max_output_tokens: 50,
                stop_sequences: None,
            },
            safety_settings: Self::get_default_safety_settings(),
        };
        
        let response = temp_client
            .post(&url)
            .header("Content-Type", "application/json")
            .header("x-goog-api-key", api_key)
            .json(&test_request)
            .timeout(Duration::from_secs(30))
            .send()
            .await?;

        if response.status().is_success() {
            log::info!("[GeminiProvider] API é‡‘é‘°é©—è­‰æˆåŠŸ");
            Ok(true)
        } else {
            log::warn!("[GeminiProvider] API é‡‘é‘°é©—è­‰å¤±æ•—: {}", response.status());
            Ok(false)
        }
    }

    async fn estimate_cost(&self, request: &AIGenerationRequest) -> Result<Option<f64>> {
        // Gemini çš„è¨ˆè²»æ–¹å¼
        let cost_per_input_token = if request.model.contains("1.5-pro") {
            0.0000035
        } else if request.model.contains("1.5-flash") {
            0.000000075
        } else {
            0.0000005 // gemini-pro
        };
        
        let cost_per_output_token = cost_per_input_token * 3.0; // è¼¸å‡ºé€šå¸¸æ¯”è¼¸å…¥è²´3å€
        
        // ä¼°ç®— token æ•¸ï¼ˆå¤§ç´„æ¯4å€‹å­—ç¬¦1å€‹tokenï¼‰
        let estimated_input_tokens = (request.prompt.len() / 4) as f64;
        let estimated_output_tokens = request.params.max_tokens as f64;
        
        let estimated_cost = (estimated_input_tokens * cost_per_input_token) + 
                           (estimated_output_tokens * cost_per_output_token);
        
        Ok(Some(estimated_cost))
    }

    fn default_params(&self) -> AIGenerationParams {
        AIGenerationParams {
            temperature: 0.9,
            max_tokens: 2048,
            top_p: Some(1.0),
            presence_penalty: None, // Gemini ä¸æ”¯æ´
            frequency_penalty: None, // Gemini ä¸æ”¯æ´
            stop: None,
        }
    }

    fn requires_api_key(&self) -> bool {
        true
    }

    fn supports_custom_endpoint(&self) -> bool {
        false // Gemini é€šå¸¸ä½¿ç”¨æ¨™æº–ç«¯é»
    }
}