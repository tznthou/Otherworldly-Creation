use crate::database::{connection::create_connection, models::*};
use crate::services::ai_providers::{AIProviderFactory, ProviderConfig};
use anyhow::{Result, anyhow};
use chrono::Utc;
use rusqlite::{params, Row};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use uuid::Uuid;

// éŸ¿æ‡‰çµæ§‹é«”
#[derive(Debug, Serialize)]
pub struct AIProviderResponse {
    pub success: bool,
    pub data: Option<crate::database::models::AIProvider>,
    pub providers: Option<Vec<crate::database::models::AIProvider>>,
    pub error: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct AIProviderTestResult {
    pub success: bool,
    pub provider_type: String,
    pub models: Option<Vec<serde_json::Value>>,
    pub error: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct AIGenerationResult {
    pub success: bool,
    pub generated_text: Option<String>,
    pub model: Option<String>,
    pub usage: Option<serde_json::Value>,
    pub provider_id: Option<String>,
    pub error: Option<String>,
}

// è«‹æ±‚çµæ§‹é«”
#[derive(Debug, Deserialize)]
pub struct AIGenerationRequestData {
    pub provider_id: String,
    pub model: String,
    pub prompt: String,
    pub system_prompt: Option<String>,
    pub project_id: String,
    pub chapter_id: String,
    pub position: Option<usize>,  // æ–°å¢ï¼šæ¸¸æ¨™ä½ç½®ï¼Œç”¨æ–¼ä¸Šä¸‹æ–‡æ§‹å»º
    pub temperature: Option<f64>,
    pub max_tokens: Option<i32>,
    pub top_p: Option<f64>,
    pub presence_penalty: Option<f64>,
    pub frequency_penalty: Option<f64>,
    pub stop: Option<Vec<String>>,
}

// åŠ å¯†å·¥å…·å‡½æ•¸
fn encrypt_api_key(api_key: &str) -> Result<String> {
    // ç°¡å–®çš„base64ç·¨ç¢¼ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰ä½¿ç”¨æ›´å¼·çš„åŠ å¯†
    use base64::{Engine as _, engine::general_purpose};
    Ok(general_purpose::STANDARD.encode(api_key))
}

fn decrypt_api_key(encrypted_key: &str) -> Result<String> {
    // å°æ‡‰çš„è§£ç¢¼
    use base64::{Engine as _, engine::general_purpose};
    general_purpose::STANDARD.decode(encrypted_key)
        .map_err(|e| anyhow!("è§£å¯†APIé‡‘é‘°å¤±æ•—: {}", e))
        .and_then(|bytes| String::from_utf8(bytes).map_err(|e| anyhow!("è½‰æ›å­—ç¬¦ä¸²å¤±æ•—: {}", e)))
}

// å¾æ•¸æ“šåº«è¡Œæ§‹å»ºAIProvider
fn build_ai_provider_from_row(row: &Row) -> rusqlite::Result<crate::database::models::AIProvider> {
    Ok(crate::database::models::AIProvider {
        id: row.get("id")?,
        name: row.get("name")?,
        provider_type: row.get("provider_type")?,
        api_key_encrypted: row.get("api_key_encrypted")?,
        endpoint: row.get("endpoint")?,
        model: row.get("model")?,
        is_enabled: row.get("is_enabled")?,
        settings_json: row.get("settings_json")?,
        created_at: row.get("created_at")?,
        updated_at: row.get("updated_at")?,
    })
}

// å¾AIProvideræ¨¡å‹è½‰æ›ç‚ºProviderConfig
fn provider_to_config(provider: &crate::database::models::AIProvider) -> Result<ProviderConfig> {
    let api_key = if let Some(encrypted) = &provider.api_key_encrypted {
        Some(decrypt_api_key(encrypted)?)
    } else {
        None
    };

    let settings: HashMap<String, serde_json::Value> = if let Some(settings_json) = &provider.settings_json {
        serde_json::from_str(settings_json).unwrap_or_default()
    } else {
        HashMap::new()
    };

    Ok(ProviderConfig {
        id: provider.id.clone(),
        name: provider.name.clone(),
        provider_type: provider.provider_type.clone(),
        api_key,
        endpoint: provider.endpoint.clone(),
        model: provider.model.clone(),
        is_enabled: provider.is_enabled,
        settings,
    })
}

/// ç²å–æ‰€æœ‰AIæä¾›è€…
#[tauri::command]
pub async fn get_ai_providers() -> Result<AIProviderResponse, String> {
    log::info!("ç²å–æ‰€æœ‰AIæä¾›è€…");
    
    let conn = create_connection().map_err(|e| e.to_string())?;
    
    let mut stmt = conn.prepare(
        "SELECT id, name, provider_type, api_key_encrypted, endpoint, model, 
         is_enabled, settings_json, created_at, updated_at 
         FROM ai_providers ORDER BY created_at"
    ).map_err(|e| e.to_string())?;
    
    let provider_iter = stmt.query_map([], build_ai_provider_from_row)
        .map_err(|e| e.to_string())?;
    
    let mut providers = Vec::new();
    for provider in provider_iter {
        providers.push(provider.map_err(|e| e.to_string())?);
    }
    
    Ok(AIProviderResponse {
        success: true,
        data: None,
        providers: Some(providers),
        error: None,
    })
}

/// å‰µå»ºæ–°çš„AIæä¾›è€…
#[tauri::command]
pub async fn create_ai_provider(request: CreateAIProviderRequest) -> Result<AIProviderResponse, String> {
    log::info!("å‰µå»ºAIæä¾›è€…: {}", request.name);
    
    let conn = create_connection().map_err(|e| e.to_string())?;
    let id = Uuid::new_v4().to_string();
    let now = Utc::now();
    
    // åŠ å¯†APIé‡‘é‘°ï¼ˆå¦‚æœæœ‰ï¼‰
    let encrypted_api_key = if let Some(api_key) = &request.api_key {
        Some(encrypt_api_key(api_key).map_err(|e| e.to_string())?)
    } else {
        None
    };
    
    conn.execute(
        "INSERT INTO ai_providers (
            id, name, provider_type, api_key_encrypted, endpoint, model, 
            is_enabled, settings_json, created_at, updated_at
        ) VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8, ?9, ?10)",
        params![
            id,
            request.name,
            request.provider_type,
            encrypted_api_key,
            request.endpoint,
            request.model,
            request.is_enabled.unwrap_or(true),
            request.settings_json,
            now,
            now
        ],
    ).map_err(|e| e.to_string())?;
    
    // è¿”å›å‰µå»ºçš„æä¾›è€…
    let provider = crate::database::models::AIProvider {
        id: id.clone(),
        name: request.name,
        provider_type: request.provider_type,
        api_key_encrypted: encrypted_api_key,
        endpoint: request.endpoint,
        model: request.model,
        is_enabled: request.is_enabled.unwrap_or(true),
        settings_json: request.settings_json,
        created_at: now,
        updated_at: now,
    };
    
    Ok(AIProviderResponse {
        success: true,
        data: Some(provider),
        providers: None,
        error: None,
    })
}

/// æ›´æ–°AIæä¾›è€…
#[tauri::command]
pub async fn update_ai_provider(request: UpdateAIProviderRequest) -> Result<AIProviderResponse, String> {
    log::info!("æ›´æ–°AIæä¾›è€…: {}", request.id);
    
    let conn = create_connection().map_err(|e| e.to_string())?;
    let now = Utc::now();
    
    // æ§‹å»ºå‹•æ…‹SQLæ›´æ–°èªå¥
    let mut sql_parts = Vec::new();
    let mut params: Vec<Box<dyn rusqlite::ToSql>> = Vec::new();
    
    if let Some(name) = &request.name {
        sql_parts.push("name = ?");
        params.push(Box::new(name.clone()));
    }
    
    if let Some(api_key) = &request.api_key {
        let encrypted = encrypt_api_key(api_key).map_err(|e| e.to_string())?;
        sql_parts.push("api_key_encrypted = ?");
        params.push(Box::new(encrypted));
    }
    
    if let Some(endpoint) = &request.endpoint {
        sql_parts.push("endpoint = ?");
        params.push(Box::new(endpoint.clone()));
    }
    
    if let Some(model) = &request.model {
        sql_parts.push("model = ?");
        params.push(Box::new(model.clone()));
    }
    
    if let Some(is_enabled) = request.is_enabled {
        sql_parts.push("is_enabled = ?");
        params.push(Box::new(is_enabled));
    }
    
    if let Some(settings_json) = &request.settings_json {
        sql_parts.push("settings_json = ?");
        params.push(Box::new(settings_json.clone()));
    }
    
    sql_parts.push("updated_at = ?");
    params.push(Box::new(now));
    params.push(Box::new(request.id.clone()));
    
    let sql = format!(
        "UPDATE ai_providers SET {} WHERE id = ?",
        sql_parts.join(", ")
    );
    
    conn.execute(&sql, rusqlite::params_from_iter(params.iter()))
        .map_err(|e| e.to_string())?;
    
    Ok(AIProviderResponse {
        success: true,
        data: None,
        providers: None,
        error: None,
    })
}

/// åˆªé™¤AIæä¾›è€…
#[tauri::command]
pub async fn delete_ai_provider(id: String) -> Result<AIProviderResponse, String> {
    log::info!("åˆªé™¤AIæä¾›è€…: {}", id);
    
    let conn = create_connection().map_err(|e| e.to_string())?;
    
    conn.execute("DELETE FROM ai_providers WHERE id = ?1", params![id])
        .map_err(|e| e.to_string())?;
    
    Ok(AIProviderResponse {
        success: true,
        data: None,
        providers: None,
        error: None,
    })
}

/// æ¸¬è©¦AIæä¾›è€…é€£æ¥
#[tauri::command]
pub async fn test_ai_provider(id: String) -> Result<AIProviderTestResult, String> {
    log::info!("æ¸¬è©¦AIæä¾›è€…: {}", id);
    
    // å…ˆå¾æ•¸æ“šåº«ç²å–æä¾›è€…è³‡è¨Šï¼Œç„¶å¾Œé—œé–‰é€£æ¥
    let (config, provider_type) = {
        let conn = create_connection().map_err(|e| e.to_string())?;
        
        let mut stmt = conn.prepare(
            "SELECT id, name, provider_type, api_key_encrypted, endpoint, model, 
             is_enabled, settings_json, created_at, updated_at 
             FROM ai_providers WHERE id = ?1"
        ).map_err(|e| e.to_string())?;
        
        let provider = stmt.query_row(params![id], build_ai_provider_from_row)
            .map_err(|e| e.to_string())?;
        
        let config = provider_to_config(&provider).map_err(|e| e.to_string())?;
        (config, provider.provider_type)
    };
    
    // å‰µå»ºæä¾›è€…å¯¦ä¾‹ä¸¦æ¸¬è©¦
    match AIProviderFactory::create_provider(&config) {
        Ok(provider_instance) => {
            match provider_instance.check_availability().await {
                Ok(true) => {
                    // å˜—è©¦ç²å–æ¨¡å‹åˆ—è¡¨
                    let models = provider_instance.get_models().await
                        .map(|models| {
                            models.into_iter()
                                .map(|model| serde_json::json!({
                                    "id": model.id,
                                    "name": model.name,
                                    "description": model.description,
                                    "max_tokens": model.max_tokens,
                                    "supports_streaming": model.supports_streaming,
                                    "cost_per_token": model.cost_per_token,
                                }))
                                .collect::<Vec<_>>()
                        })
                        .ok();
                    
                    Ok(AIProviderTestResult {
                        success: true,
                        provider_type: provider_type.clone(),
                        models,
                        error: None,
                    })
                }
                Ok(false) => {
                    Ok(AIProviderTestResult {
                        success: false,
                        provider_type: provider_type.clone(),
                        models: None,
                        error: Some("æœå‹™ä¸å¯ç”¨".to_string()),
                    })
                }
                Err(e) => {
                    Ok(AIProviderTestResult {
                        success: false,
                        provider_type: provider_type.clone(),
                        models: None,
                        error: Some(e.to_string()),
                    })
                }
            }
        }
        Err(e) => {
            Ok(AIProviderTestResult {
                success: false,
                provider_type: provider_type,
                models: None,
                error: Some(format!("å‰µå»ºæä¾›è€…å¯¦ä¾‹å¤±æ•—: {}", e)),
            })
        }
    }
}

/// ä½¿ç”¨æŒ‡å®šæä¾›è€…ç”Ÿæˆæ–‡æœ¬ï¼ˆå¸¶ä¸Šä¸‹æ–‡æ§‹å»ºï¼‰
#[tauri::command]
pub async fn generate_ai_text(request: AIGenerationRequestData) -> Result<AIGenerationResult, String> {
    log::info!("ä½¿ç”¨AIæä¾›è€…ç”Ÿæˆæ–‡æœ¬ï¼ˆå¸¶ä¸Šä¸‹æ–‡ï¼‰: {} -> {}", request.provider_id, request.model);
    log::info!("é …ç›®ID: {}, ç« ç¯€ID: {}, ä½ç½®: {:?}", request.project_id, request.chapter_id, request.position);
    
    let start_time = std::time::Instant::now();
    
    // å…ˆå¾æ•¸æ“šåº«ç²å–æä¾›è€…è³‡è¨Šï¼Œç„¶å¾Œé—œé–‰é€£æ¥
    let config = {
        let conn = create_connection().map_err(|e| e.to_string())?;
        
        let mut stmt = conn.prepare(
            "SELECT id, name, provider_type, api_key_encrypted, endpoint, model, 
             is_enabled, settings_json, created_at, updated_at 
             FROM ai_providers WHERE id = ?1 AND is_enabled = 1"
        ).map_err(|e| e.to_string())?;
        
        let provider = stmt.query_row(params![request.provider_id], build_ai_provider_from_row)
            .map_err(|e| format!("æ‰¾ä¸åˆ°æˆ–æœªå•Ÿç”¨çš„AIæä¾›è€…: {}", e))?;
        
        provider_to_config(&provider).map_err(|e| e.to_string())?
    };
    
    // ğŸ”¥ æ ¸å¿ƒä¿®å¾©ï¼šæ·»åŠ ä¸Šä¸‹æ–‡æ§‹å»ºåŠŸèƒ½ï¼ˆå’ŒèˆŠç‰ˆ generate_with_context ä¸€æ¨£ï¼‰
    let enhanced_prompt = if let Some(position) = request.position {
        log::info!("æ§‹å»ºä¸Šä¸‹æ–‡ï¼Œä½ç½®: {}", position);
        
        // 1. æ§‹å»ºä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨å’ŒèˆŠç‰ˆç›¸åŒçš„é‚è¼¯ï¼‰
        match crate::commands::context::build_context(
            request.project_id.clone(),
            request.chapter_id.clone(), 
            position,
            Some("zh-TW".to_string())
        ).await {
            Ok(context) => {
                log::info!("ä¸Šä¸‹æ–‡æ§‹å»ºæˆåŠŸï¼Œé•·åº¦: {} å­—ç¬¦", context.len());
                
                // 2. å¦‚æœè¨­å®šäº†æœ€å¤§ tokenï¼Œé€²è¡Œå£“ç¸®ï¼ˆå’ŒèˆŠç‰ˆä¸€æ¨£ï¼‰
                let final_context = if let Some(max_tokens) = request.max_tokens {
                    if max_tokens > 1000 {  // é ç•™ä¸€äº›ç©ºé–“çµ¦ç”Ÿæˆå…§å®¹
                        let max_context_tokens = (max_tokens / 2) as usize; // ä¸Šä¸‹æ–‡ä½”ä¸€åŠ token
                        match crate::commands::context::compress_context(context.clone(), max_context_tokens).await {
                            Ok(compressed) => {
                                log::info!("ä¸Šä¸‹æ–‡å£“ç¸®æˆåŠŸï¼Œå¾ {} å­—ç¬¦å£“ç¸®åˆ° {} å­—ç¬¦", context.len(), compressed.len());
                                compressed
                            }
                            Err(e) => {
                                log::warn!("ä¸Šä¸‹æ–‡å£“ç¸®å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹ä¸Šä¸‹æ–‡: {}", e);
                                context
                            }
                        }
                    } else {
                        context
                    }
                } else {
                    context
                };
                
                // 3. æ§‹å»ºå®Œæ•´çš„æç¤ºè©ï¼šä¸Šä¸‹æ–‡ + åŸå§‹æç¤º
                let full_prompt = if request.prompt.trim().is_empty() {
                    // å¦‚æœæ²’æœ‰ç‰¹åˆ¥æç¤ºï¼Œä½¿ç”¨é è¨­çš„çºŒå¯«æç¤º
                    format!("{}

è«‹æ ¹æ“šä»¥ä¸Šå…§å®¹ç¹¼çºŒå‰µä½œï¼Œä¿æŒä¸€è‡´çš„å¯«ä½œé¢¨æ ¼å’Œæ•…äº‹ç™¼å±•ã€‚", final_context)
                } else {
                    // ä½¿ç”¨è‡ªå®šç¾©æç¤º
                    format!("{}

{}", final_context, request.prompt)
                };
                
                log::info!("æœ€çµ‚æç¤ºè©é•·åº¦: {} å­—ç¬¦", full_prompt.len());
                full_prompt
            }
            Err(e) => {
                log::warn!("æ§‹å»ºä¸Šä¸‹æ–‡å¤±æ•—ï¼Œä½¿ç”¨åŸå§‹æç¤º: {}", e);
                request.prompt.clone()
            }
        }
    } else {
        // æ²’æœ‰ä½ç½®ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æç¤º
        log::info!("æ²’æœ‰ä½ç½®ä¿¡æ¯ï¼Œä½¿ç”¨åŸå§‹æç¤º");
        request.prompt.clone()
    };

    // å‰µå»ºæä¾›è€…å¯¦ä¾‹
    let provider_instance = AIProviderFactory::create_provider(&config)
        .map_err(|e| format!("å‰µå»ºæä¾›è€…å¯¦ä¾‹å¤±æ•—: {}", e))?;
    
    // æ§‹å»ºç”Ÿæˆè«‹æ±‚ï¼ˆä½¿ç”¨å¢å¼·çš„ä¸Šä¸‹æ–‡æç¤ºè©ï¼‰
    let generation_request = crate::services::ai_providers::AIGenerationRequest {
        model: request.model.clone(),
        prompt: enhanced_prompt, // ğŸ”¥ ä½¿ç”¨å¸¶ä¸Šä¸‹æ–‡çš„å¢å¼·æç¤ºè©
        system_prompt: request.system_prompt.clone(),
        params: crate::services::ai_providers::AIGenerationParams {
            temperature: request.temperature.unwrap_or(0.7),
            max_tokens: request.max_tokens.unwrap_or(500), // ğŸ”¥ æ”¹ç‚º 500ï¼Œé©åˆå°èªªçºŒå¯«
            top_p: request.top_p,
            presence_penalty: request.presence_penalty,
            frequency_penalty: request.frequency_penalty,
            stop: request.stop.clone(),
        },
    };
    
    // ç”Ÿæˆæ–‡æœ¬
    match provider_instance.generate_text(generation_request).await {
        Ok(response) => {
            let _generation_time_ms = start_time.elapsed().as_millis() as i32;
            
            // å°‡çµæœä¿å­˜åˆ°æ­·å²è¨˜éŒ„ï¼ˆå¯é¸ï¼‰
            // TODO: å¯¦ç¾æ­·å²è¨˜éŒ„ä¿å­˜
            
            Ok(AIGenerationResult {
                success: true,
                generated_text: Some(response.text),
                model: Some(response.model),
                usage: response.usage.map(|usage| serde_json::json!({
                    "prompt_tokens": usage.prompt_tokens,
                    "completion_tokens": usage.completion_tokens,
                    "total_tokens": usage.total_tokens,
                })),
                provider_id: Some(request.provider_id),
                error: None,
            })
        }
        Err(e) => {
            Ok(AIGenerationResult {
                success: false,
                generated_text: None,
                model: None,
                usage: None,
                provider_id: Some(request.provider_id),
                error: Some(e.to_string()),
            })
        }
    }
}

/// ç²å–æ”¯æ´çš„AIæä¾›è€…é¡å‹
#[tauri::command]
pub async fn get_supported_ai_provider_types() -> Result<Vec<String>, String> {
    Ok(AIProviderFactory::supported_providers().iter().map(|s| s.to_string()).collect())
}