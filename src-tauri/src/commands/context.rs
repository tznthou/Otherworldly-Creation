use crate::database::{get_db, models::*};
use crate::utils::language_purity::LanguagePurityEnforcer;
use rusqlite::Result as SqliteResult;
use serde::{Deserialize, Serialize};
use serde_json::Value;
use tauri::command;

/// å¾ç« ç¯€å…§å®¹ä¸­æå–ç­†è¨˜
fn extract_chapter_notes(content_json: &str) -> Option<String> {
    // å˜—è©¦è§£æç« ç¯€å…§å®¹çš„ JSON
    if let Ok(content) = serde_json::from_str::<Value>(content_json) {
        // æŸ¥æ‰¾ metadata.notes
        if let Some(obj) = content.as_object() {
            if let Some(metadata) = obj.get("metadata") {
                if let Some(notes) = metadata.get("notes") {
                    if let Some(notes_str) = notes.as_str() {
                        if !notes_str.trim().is_empty() {
                            log::info!("âœ… æ‰¾åˆ°ç« ç¯€ç­†è¨˜ï¼Œé•·åº¦: {} å­—ç¬¦", notes_str.len());
                            return Some(notes_str.to_string());
                        }
                    }
                }
            }
        }
        
        // å¦‚æœæ˜¯é™£åˆ—æ ¼å¼ï¼Œæª¢æŸ¥æ¯å€‹å…ƒç´ 
        if let Some(array) = content.as_array() {
            for item in array {
                if let Some(obj) = item.as_object() {
                    if let Some(metadata) = obj.get("metadata") {
                        if let Some(notes) = metadata.get("notes") {
                            if let Some(notes_str) = notes.as_str() {
                                if !notes_str.trim().is_empty() {
                                    log::info!("âœ… åœ¨é™£åˆ—ä¸­æ‰¾åˆ°ç« ç¯€ç­†è¨˜ï¼Œé•·åº¦: {} å­—ç¬¦", notes_str.len());
                                    return Some(notes_str.to_string());
                                }
                            }
                        }
                    }
                }
            }
        }
    }
    
    log::debug!("ğŸ” æœªæ‰¾åˆ°ç« ç¯€ç­†è¨˜");
    None
}

/// å­—ç¬¦æ¸…ç†å‡½æ•¸ - ä¿ç•™åˆæ³•çš„æ–‡å­—å­—ç¬¦ï¼ŒåŒ…æ‹¬ä¸­æ–‡
fn clean_text(text: &str) -> String {
    text.chars()
        .filter(|c| {
            // ä¿ç•™æ‰€æœ‰åˆæ³•çš„æ–‡å­—å­—ç¬¦ï¼ŒåŒ…æ‹¬ä¸­æ–‡
            c.is_alphanumeric() || // åŒ…æ‹¬ä¸­æ–‡å­—ç¬¦
            c.is_whitespace() ||   // ç©ºç™½å­—ç¬¦
            ".,!?;:\"'()[]{}ã€Œã€ã€ã€ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€ˆã€‰".contains(*c) || 
            *c == '-' || *c == '_' || *c == '/' || *c == '\\' || 
            *c == '=' || *c == '+' || *c == '*' || *c == '&' ||
            *c == '%' || *c == '$' || *c == '#' || *c == '@'
        })
        .collect()
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ContextStats {
    pub total_characters: usize,
    pub estimated_tokens: usize,
    pub chapter_count: usize,
    pub character_count: usize,
}

/// ç³»çµ±æç¤ºå»ºæ§‹å™¨ - åˆ†é›¢å›ºå®šæŒ‡ä»¤ä»¥ç¯€çœ tokenï¼ˆç°¡åŒ–ç‰ˆï¼‰
#[derive(Debug, Clone)]
pub struct SystemPromptBuilder {
    pub project_type: Option<String>,
}

impl SystemPromptBuilder {
    pub fn new(project_type: Option<String>) -> Self {
        Self { project_type }
    }

    /// å»ºæ§‹ç³»çµ±æç¤ºï¼Œå°ˆæ³¨æ–¼ç¹é«”ä¸­æ–‡å°èªªçºŒå¯«
    pub fn build_system_prompt(&self) -> String {
        let enforcer = LanguagePurityEnforcer::new();
        
        let base_instructions = "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä¸­æ–‡å°èªªçºŒå¯«åŠ©æ‰‹ã€‚ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šæä¾›çš„ä¸Šä¸‹æ–‡è³‡è¨Šï¼Œåœ¨æŒ‡å®šä½ç½®æ’å…¥åˆé©çš„çºŒå¯«å…§å®¹ã€‚

æ ¸å¿ƒè¦æ±‚:
- åœ¨ [CONTINUE HERE] æ¨™è¨˜è™•æ’å…¥çºŒå¯«å…§å®¹
- **é‡è¦**ï¼šçµ•å°ä¸è¦é‡è¤‡ã€è¤‡è£½æˆ–é‡å¯«ç¾æœ‰å…§å®¹
- **é‡è¦**ï¼šåªæä¾›å…¨æ–°çš„çºŒå¯«å…§å®¹ï¼Œå»¶çºŒæ•…äº‹æƒ…ç¯€
- **é‡è¦**ï¼šå¦‚æœçœ‹åˆ°ç¾æœ‰å…§å®¹å·²ç¶“å®Œæ•´ï¼Œè«‹æä¾›ä¸‹ä¸€å€‹æƒ…ç¯€ç™¼å±•
- ä¿æŒè§’è‰²ä¸€è‡´æ€§å’Œå°è©±é¢¨æ ¼
- ç¢ºä¿æƒ…ç¯€é€£è²«å’Œç´°ç¯€ä¸€è‡´
- CRITICAL: åš´æ ¼ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œçµ•å°ä¸å…è¨±æ··é›œä»»ä½•è‹±æ–‡å–®è©æˆ–ç°¡é«”å­—
- æ‰€æœ‰æè¿°ã€å‹•ä½œã€å°è©±éƒ½å¿…é ˆä½¿ç”¨ç´”æ­£ç¹é«”ä¸­æ–‡
- ç¦æ­¢ä½¿ç”¨è‹±æ–‡æ‹¼éŸ³ã€è‹±æ–‡ç¸®å¯«æˆ–ä»»ä½•è‹±æ–‡è¡¨é”
- åªæä¾›çºŒå¯«æ–‡æœ¬ï¼Œç„¡éœ€è§£é‡‹æˆ–è©•è«–

çºŒå¯«æŒ‡å°åŸå‰‡:
- å¦‚æœç¾æœ‰å…§å®¹å·²ç¶“çµæŸåœ¨å°è©±æˆ–å‹•ä½œï¼Œè«‹çºŒå¯«ä¸‹ä¸€å€‹å ´æ™¯æˆ–åæ‡‰
- å¦‚æœç¾æœ‰å…§å®¹æ˜¯æè¿°æ€§æ–‡å­—ï¼Œè«‹çºŒå¯«è§’è‰²çš„æƒ³æ³•ã€å°è©±æˆ–æ–°å‹•ä½œ
- æ¨é€²æƒ…ç¯€ç™¼å±•ï¼Œä¸è¦åœç•™åœ¨å·²æè¿°çš„å…§å®¹ä¸Š
- æ¯æ¬¡çºŒå¯«æ‡‰è©²å¸¶ä¾†æ–°çš„ä¿¡æ¯æˆ–æ¨é€²æ•…äº‹";

        let genre_specific = if let Some(project_type) = &self.project_type {
            let is_light_novel = project_type.to_lowercase().contains("è¼•å°èªª") || 
                               project_type.to_lowercase().contains("è½»å°è¯´") ||
                               project_type.to_lowercase().contains("light novel");
            
            if is_light_novel {
                "

è¼•å°èªªé¢¨æ ¼è¦æ±‚:
- é©ç•¶åŠ å…¥è§’è‰²å…§å¿ƒç¨ç™½
- ä¿æŒç¯€å¥æ˜å¿«ï¼Œå°è©±ç”Ÿå‹•
- å¯ä»¥é©ç•¶ä½¿ç”¨æ“¬è²è©å’Œè¡¨æƒ…æå¯«
- åš´ç¦ä½¿ç”¨è‹±æ–‡å–®è©æˆ–ç°¡é«”å­—"
            } else {
                ""
            }
        } else {
            ""
        };

        // ä½¿ç”¨èªè¨€ç´”åº¦å¢å¼·å™¨ç”Ÿæˆå¼·åŒ–çš„ç³»çµ±æç¤º
        let enhanced_prompt = format!("{}{}", base_instructions, genre_specific);
        enforcer.generate_enhanced_system_prompt(&enhanced_prompt)
    }
}

/// ç”¨æˆ¶ä¸Šä¸‹æ–‡å»ºæ§‹å™¨ - ç²¾ç°¡çš„å…§å®¹ä¸Šä¸‹æ–‡
#[derive(Debug)]
pub struct UserContextBuilder {
    pub project: Project,
    pub chapter: Chapter,
    pub characters: Vec<Character>,
    pub position: usize,
}

impl UserContextBuilder {
    pub fn new(project: Project, chapter: Chapter, characters: Vec<Character>, position: usize) -> Self {
        Self { project, chapter, characters, position }
    }

    /// å»ºæ§‹ç²¾ç°¡çš„ç”¨æˆ¶ä¸Šä¸‹æ–‡
    pub fn build_user_context(&self) -> String {
        let mut context = String::new();
        
        // é …ç›®åŸºæœ¬ä¿¡æ¯ - ä½¿ç”¨æ¥µç°¡æ¨™ç±¤
        context.push_str(&format!("Title: {}\n", clean_text(&self.project.name)));
        
        if let Some(desc) = &self.project.description {
            let short_desc = clean_text(desc).chars().take(150).collect::<String>();
            context.push_str(&format!("Summary: {}\n", short_desc));
        }
        
        if let Some(project_type) = &self.project.r#type {
            context.push_str(&format!("Genre: {}\n", clean_text(project_type)));
        }
        
        // è§’è‰²ä¿¡æ¯ - åªä¿ç•™æ ¸å¿ƒå±¬æ€§
        if !self.characters.is_empty() {
            context.push_str("\nCharacters:\n");
            for character in &self.characters {
                let char_desc = character.description.as_deref().unwrap_or("")
                    .chars().take(80).collect::<String>(); // é™åˆ¶æ¯å€‹è§’è‰²æè¿°ç‚º80å­—ç¬¦
                context.push_str(&format!("- {}: {}\n", character.name, char_desc));
                
                // ç°¡åŒ–å±¬æ€§é¡¯ç¤º
                if let Some(attrs) = &character.attributes {
                    if let Ok(attrs_json) = serde_json::from_str::<serde_json::Value>(attrs) {
                        if let Some(obj) = attrs_json.as_object() {
                            let mut key_attrs = Vec::new();
                            for (key, value) in obj.iter().take(3) { // æœ€å¤šé¡¯ç¤º3å€‹å±¬æ€§
                                if let Some(v) = value.as_str() {
                                    if !v.is_empty() && v.len() < 30 {
                                        key_attrs.push(format!("{}:{}", key, v));
                                    }
                                }
                            }
                            if !key_attrs.is_empty() {
                                context.push_str(&format!("  ({})\n", key_attrs.join(", ")));
                            }
                        }
                    }
                }
            }
        }
        
        // ç•¶å‰ç« ç¯€å…§å®¹
        context.push_str(&format!("\nChapter: {}\n", clean_text(&self.chapter.title)));
        context.push_str("Content:\n");
        context.push_str(&self.extract_relevant_content());
        context.push_str("\n[CONTINUE HERE]");
        
        context
    }
    
    /// æ™ºèƒ½æå–ç›¸é—œå…§å®¹
    fn extract_relevant_content(&self) -> String {
        if let Some(content) = &self.chapter.content {
            let content_chars: Vec<char> = content.chars().collect();
            let char_len = content_chars.len();
            let char_position = self.position.min(char_len);
            
            // åˆ†å‰²å…§å®¹
            let before_cursor: String = content_chars[..char_position].iter().collect();
            let after_cursor: String = content_chars[char_position..].iter().collect();
            
            let mut result = String::new();
            
            // è™•ç†æ¸¸æ¨™å‰çš„å…§å®¹ - å‹•æ…‹èª¿æ•´é•·åº¦
            let cleaned_before = clean_text(&before_cursor);
            const MAX_BEFORE_CHARS: usize = 800; // æ¸›å°‘åˆ°800å­—ç¬¦
            
            if cleaned_before.chars().count() > MAX_BEFORE_CHARS {
                let before_chars: Vec<char> = cleaned_before.chars().collect();
                let total_chars = before_chars.len();
                let start_pos = total_chars.saturating_sub(MAX_BEFORE_CHARS);
                
                // æ‰¾åˆ°åˆé©çš„é–‹å§‹é»ï¼ˆå¥å­é‚Šç•Œï¼‰
                let remaining_text: String = before_chars[start_pos..].iter().collect();
                let adjusted_start = remaining_text
                    .find(|c| c == '.' || c == '!' || c == '?' || c == '\n' || c == 'ã€‚' || c == 'ï¼' || c == 'ï¼Ÿ')
                    .map(|i| i + 1)
                    .unwrap_or(0);
                
                result.push_str("...(å‰æ–‡çœç•¥)...
");
                let final_chars: Vec<char> = remaining_text.chars().collect();
                let final_text: String = final_chars[adjusted_start.min(final_chars.len())..].iter().collect();
                result.push_str(&final_text);
            } else {
                result.push_str(&cleaned_before);
            }
            
            // æ·»åŠ æ˜ç¢ºçš„çºŒå¯«æ¨™è¨˜ - æ›´åŠ çªå‡º
            result.push_str("

>>> [çºŒå¯«ä½ç½®ï¼šè«‹åœ¨æ­¤è™•ç¹¼çºŒæ•…äº‹ï¼Œä¸è¦é‡è¤‡ä¸Šè¿°å…§å®¹] <<<

");
            
            // è™•ç†æ¸¸æ¨™å¾Œçš„å…§å®¹ - å¦‚æœæœ‰å¾ŒçºŒå…§å®¹ï¼Œæ˜ç¢ºæ¨™ç¤ºé€™æ˜¯ã€Œæœªä¾†å…§å®¹ã€
            if !after_cursor.is_empty() {
                let cleaned_after = clean_text(&after_cursor);
                const MAX_AFTER_CHARS: usize = 100; // æ¸›å°‘åˆ°100å­—ç¬¦
                
                if cleaned_after.chars().count() > MAX_AFTER_CHARS {
                    let after_chars: Vec<char> = cleaned_after.chars().collect();
                    let truncated_chars: Vec<char> = after_chars[..MAX_AFTER_CHARS].to_vec();
                    let truncated_after: String = truncated_chars.iter().collect();
                    
                    let end_pos = truncated_after
                        .rfind(|c| c == '.' || c == '!' || c == '?' || c == '\n' || c == 'ã€‚' || c == 'ï¼' || c == 'ï¼Ÿ')
                        .unwrap_or(truncated_after.len());
                    
                    result.push_str("[æ³¨æ„ï¼šä»¥ä¸‹æ˜¯å·²å­˜åœ¨çš„å¾ŒçºŒå…§å®¹ï¼Œè«‹ä¸è¦é‡è¤‡æˆ–ä¿®æ”¹ï¼š]
");
                    let final_chars: Vec<char> = truncated_after.chars().collect();
                    let final_text: String = final_chars[..end_pos.min(final_chars.len())].iter().collect();
                    result.push_str(&final_text);
                    result.push_str("
...(å¾ŒçºŒå…§å®¹ç¹¼çºŒ)...");
                } else if cleaned_after.len() > 10 { // åªæœ‰åœ¨æœ‰æ„ç¾©çš„å…§å®¹æ™‚æ‰é¡¯ç¤º
                    result.push_str("[æ³¨æ„ï¼šä»¥ä¸‹æ˜¯å·²å­˜åœ¨çš„å¾ŒçºŒå…§å®¹ï¼Œè«‹ä¸è¦é‡è¤‡æˆ–ä¿®æ”¹ï¼š]
");
                    result.push_str(&cleaned_after);
                }
            }
            
            result
        } else {
            String::new()
        }
    }
}

/// æ§‹å»º AI çºŒå¯«çš„ä¸Šä¸‹æ–‡ï¼ˆç°¡åŒ–ç‰ˆ - å‘å¾Œå…¼å®¹ï¼‰
#[command]
pub async fn build_context(
    project_id: String,
    chapter_id: String,
    position: usize,
    _language: Option<String>,
) -> Result<String, String> {
    log::info!("æ§‹å»ºä¸Šä¸‹æ–‡ - å°ˆæ¡ˆ: {}, ç« ç¯€: {}, ä½ç½®: {} (ç°¡åŒ–ç‰ˆ)", project_id, chapter_id, position);
    
    let db = get_db().map_err(|e| e.to_string())?;
    
    // æ›´å¥½åœ°è™•ç† poisoned lock éŒ¯èª¤
    let conn = match db.lock() {
        Ok(conn) => conn,
        Err(poisoned) => {
            log::error!("è³‡æ–™åº«é–è¢« poisonedï¼Œå˜—è©¦æ¢å¾©: {}", poisoned);
            // å˜—è©¦æ¢å¾© poisoned lock
            poisoned.into_inner()
        }
    };
    
    // 1. ç²å–å°ˆæ¡ˆè³‡è¨Š
    let project: Project = conn
        .query_row(
            "SELECT id, name, description, type, novel_length, settings, created_at, updated_at FROM projects WHERE id = ?",
            [&project_id],
            |row| Ok(Project {
                id: row.get(0)?,
                name: row.get(1)?,
                description: row.get(2)?,
                r#type: row.get(3)?,
                novel_length: row.get(4)?,
                settings: row.get(5)?,
                created_at: row.get(6)?,
                updated_at: row.get(7)?,
            })
        )
        .map_err(|e| format!("ç²å–å°ˆæ¡ˆå¤±æ•—: {}", e))?;
    
    // 2. ç²å–ç•¶å‰ç« ç¯€å…§å®¹
    let chapter: Chapter = conn
        .query_row(
            "SELECT id, project_id, title, content, order_index, chapter_number, metadata, created_at, updated_at FROM chapters WHERE id = ?",
            [&chapter_id],
            |row| Ok(Chapter {
                id: row.get(0)?,
                project_id: row.get(1)?,
                title: row.get(2)?,
                content: row.get(3)?,
                order_index: row.get(4)?,
                chapter_number: row.get(5)?,
                metadata: row.get(6)?,
                created_at: row.get(7)?,
                updated_at: row.get(8)?,
            })
        )
        .map_err(|e| format!("ç²å–ç« ç¯€å¤±æ•—: {}", e))?;
    
    // 3. ç²å–å°ˆæ¡ˆçš„æ‰€æœ‰è§’è‰²
    let mut stmt = conn
        .prepare("SELECT id, project_id, name, description, attributes, avatar_url, created_at, updated_at FROM characters WHERE project_id = ?")
        .map_err(|e| e.to_string())?;
    
    let characters: Vec<Character> = stmt
        .query_map([&project_id], |row| {
            Ok(Character {
                id: row.get(0)?,
                project_id: row.get(1)?,
                name: row.get(2)?,
                description: row.get(3)?,
                attributes: row.get(4)?,
                avatar_url: row.get(5)?,
                created_at: row.get(6)?,
                updated_at: row.get(7)?,
            })
        })
        .map_err(|e| e.to_string())?
        .collect::<SqliteResult<Vec<_>>>()
        .map_err(|e| e.to_string())?;
    
    // 4. ç²å–è§’è‰²é—œä¿‚
    let mut stmt = conn
        .prepare("
            SELECT cr.*, c1.name as from_name, c2.name as to_name 
            FROM character_relationships cr
            JOIN characters c1 ON cr.from_character_id = c1.id
            JOIN characters c2 ON cr.to_character_id = c2.id
            WHERE c1.project_id = ?
        ")
        .map_err(|e| e.to_string())?;
    
    let relationships: Vec<(String, String, String, Option<String>)> = stmt
        .query_map([&project_id], |row| {
            Ok((
                row.get::<_, String>("from_name")?,
                row.get::<_, String>("to_name")?,
                row.get::<_, String>("relationship_type")?,
                row.get::<_, Option<String>>("description")?,
            ))
        })
        .map_err(|e| e.to_string())?
        .collect::<SqliteResult<Vec<_>>>()
        .map_err(|e| e.to_string())?;
    
    // 5. æå–ç« ç¯€ç­†è¨˜
    let chapter_notes = if let Some(content) = &chapter.content {
        extract_chapter_notes(content)
    } else {
        None
    };
    
    // 6. æ§‹å»ºä¸Šä¸‹æ–‡
    let mut context = String::new();
    
    // å­—ç¬¦æ¸…ç†å‡½æ•¸
    fn clean_text(text: &str) -> String {
        text.chars()
            .filter(|c| {
                // ä¿ç•™æ‰€æœ‰åˆæ³•çš„æ–‡å­—å­—ç¬¦ï¼ŒåŒ…æ‹¬ä¸­æ–‡
                c.is_alphanumeric() || // åŒ…æ‹¬ä¸­æ–‡å­—ç¬¦
                c.is_whitespace() ||   // ç©ºç™½å­—ç¬¦
                ".,!?;:\"'()[]{}ã€Œã€ã€ã€ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€ˆã€‰".contains(*c) || 
                *c == '-' || *c == '_' || *c == '/' || *c == '\\' || 
                *c == '=' || *c == '+' || *c == '*' || *c == '&' ||
                *c == '%' || *c == '$' || *c == '#' || *c == '@'
            })
            .collect()
    }
    
    // ä½¿ç”¨ç°¡åŒ–çš„ç¹é«”ä¸­æ–‡æ¨™ç±¤
    let labels = (
        "ã€æ•…äº‹èƒŒæ™¯ã€‘",           // story_background
        "æ›¸åï¼š",                // book_name
        "ç°¡ä»‹ï¼š",                // description
        "é¡å‹ï¼š",                // genre
        "ã€è§’è‰²è¨­å®šã€‘",          // character_settings
        "  æè¿°ï¼š",              // character_description
        "ã€è§’è‰²é—œä¿‚ã€‘",          // character_relationships
        "ã€ç•¶å‰ç« ç¯€ã€‘",          // current_chapter
        "ç« ç¯€æ¨™é¡Œï¼š",            // chapter_title
        "å…§å®¹ï¼š",                // content
        "...ï¼ˆå‰æ–‡çœç•¥ï¼‰...",     // previous_content_omitted
        "ã€è«‹åœ¨æ­¤è™•çºŒå¯«ï¼ŒCRITICAL: åš´æ ¼ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œçµ•å°ç¦æ­¢ä»»ä½•è‹±æ–‡å–®è©æˆ–ç°¡é«”å­—ã€‘", // insert_continuation_here
        "ã€æ¸¸æ¨™å¾Œçš„ç¾æœ‰å…§å®¹ï¼šã€‘", // existing_content_after
        "...ï¼ˆå¾ŒçºŒå…§å®¹ç¹¼çºŒï¼‰...", // remaining_content_continues
        "ã€çºŒå¯«è¦æ±‚ã€‘",          // writing_instructions
    );
    
    // æ·»åŠ å°ˆæ¡ˆèƒŒæ™¯
    context.push_str(labels.0); // story_background
    context.push_str("\n");
    context.push_str(&format!("{}{}\n", labels.1, clean_text(&project.name))); // book_name
    if let Some(desc) = &project.description {
        context.push_str(&format!("{}{}\n", labels.2, clean_text(desc))); // description
    }
    if let Some(project_type) = &project.r#type {
        context.push_str(&format!("{}{}\n", labels.3, clean_text(project_type))); // genre
    }
    context.push_str("\n");
    
    // æ·»åŠ è§’è‰²è¨­å®š
    if !characters.is_empty() {
        context.push_str(labels.4); // character_settings
        context.push_str("\n");
        for character in &characters {
            context.push_str(&format!("â—† {}\n", character.name));
            if let Some(desc) = &character.description {
                context.push_str(&format!("{}{}\n", labels.5, desc)); // character_description
            }
            if let Some(attrs) = &character.attributes {
                // è§£æ JSON å±¬æ€§
                if let Ok(attrs_json) = serde_json::from_str::<serde_json::Value>(attrs) {
                    if let Some(obj) = attrs_json.as_object() {
                        for (key, value) in obj {
                            if let Some(v) = value.as_str() {
                                if !v.is_empty() {
                                    context.push_str(&format!("  {}ï¼š{}\n", key, v));
                                }
                            }
                        }
                    }
                }
            }
        }
        
        // æ·»åŠ è§’è‰²é—œä¿‚
        if !relationships.is_empty() {
            context.push_str("\n");
            context.push_str(labels.6); // character_relationships
            context.push_str("\n");
            for (from, to, rel_type, desc) in &relationships {
                context.push_str(&format!("- {} èˆ‡ {} çš„é—œä¿‚ï¼š{}", from, to, rel_type));
                if let Some(d) = desc {
                    context.push_str(&format!("ï¼ˆ{}ï¼‰", d));
                }
                context.push_str("\n");
            }
        }
        context.push_str("\n");
    }
    
    // æ·»åŠ ç•¶å‰ç« ç¯€å…§å®¹ï¼ˆåŒ…å«æ¸¸æ¨™å‰å¾Œçš„å…§å®¹ï¼‰
    context.push_str(labels.7); // current_chapter
    context.push_str("\n");
    context.push_str(&format!("{}{}\n", labels.8, clean_text(&chapter.title))); // chapter_title
    context.push_str(labels.9); // content
    context.push_str("\n");
    
    if let Some(content) = &chapter.content {
        let content_chars: Vec<char> = content.chars().collect();
        let char_len = content_chars.len();
        let char_position = position.min(char_len); // ç¢ºä¿ä½ç½®ä¸è¶…éå­—ç¬¦é•·åº¦
        
        // å®‰å…¨åœ°åˆ†å‰²å…§å®¹ç‚ºæ¸¸æ¨™å‰å’Œæ¸¸æ¨™å¾Œï¼ˆæŒ‰å­—ç¬¦è€Œéå­—ç¯€ï¼‰
        let before_cursor: String = content_chars[..char_position].iter().collect();
        let after_cursor: String = content_chars[char_position..].iter().collect();
        
        // è™•ç†æ¸¸æ¨™å‰çš„å…§å®¹
        let cleaned_before = clean_text(&before_cursor);
        const MAX_CONTEXT_CHARS: usize = 1000;
        
        if cleaned_before.chars().count() > MAX_CONTEXT_CHARS {
            let before_chars: Vec<char> = cleaned_before.chars().collect();
            let total_chars = before_chars.len();
            let start_pos = total_chars.saturating_sub(MAX_CONTEXT_CHARS);
            
            // å®‰å…¨åœ°æˆªå–å¾Œé¢çš„å­—ç¬¦
            let remaining_chars: Vec<char> = before_chars[start_pos..].to_vec();
            let remaining_text: String = remaining_chars.iter().collect();
            
            // æ‰¾åˆ°æœ€è¿‘çš„å¥è™Ÿæˆ–æ›è¡Œç¬¦ï¼Œé¿å…å¾å¥å­ä¸­é–“é–‹å§‹
            let adjusted_start = remaining_text
                .find(|c| c == '.' || c == '!' || c == '?' || c == '\n')
                .map(|i| i + 1)
                .unwrap_or(0);
            
            context.push_str(labels.10); // previous_content_omitted
            context.push_str("\n\n");
            // å®‰å…¨åœ°æˆªå–èª¿æ•´å¾Œçš„å…§å®¹
            let final_chars: Vec<char> = remaining_text.chars().collect();
            let final_text: String = final_chars[adjusted_start.min(final_chars.len())..].iter().collect();
            context.push_str(&final_text);
        } else {
            context.push_str(&cleaned_before);
        }
        
        // æ·»åŠ æ¸¸æ¨™ä½ç½®æ¨™è¨˜
        context.push_str("\n\n");
        context.push_str(labels.11); // insert_continuation_here
        context.push_str("\n\n");
        
        // è™•ç†æ¸¸æ¨™å¾Œçš„å…§å®¹ï¼ˆå¦‚æœæœ‰çš„è©±ï¼Œé¡¯ç¤ºä¸€å°éƒ¨åˆ†è®“ AI çŸ¥é“å¾ŒçºŒå…§å®¹ï¼‰
        if !after_cursor.is_empty() {
            let cleaned_after = clean_text(&after_cursor);
            const MAX_AFTER_CHARS: usize = 200; // åªé¡¯ç¤ºå¾Œé¢ 200 å­—
            
            if cleaned_after.chars().count() > MAX_AFTER_CHARS {
                // å®‰å…¨åœ°æˆªå–å‰ MAX_AFTER_CHARS å€‹å­—ç¬¦
                let after_chars: Vec<char> = cleaned_after.chars().collect();
                let truncated_chars: Vec<char> = after_chars[..MAX_AFTER_CHARS].to_vec();
                let truncated_after: String = truncated_chars.iter().collect();
                
                // æ‰¾åˆ°æœ€è¿‘çš„å¥è™Ÿï¼Œé¿å…åœ¨å¥å­ä¸­é–“æˆªæ–·
                let end_pos = truncated_after
                    .rfind(|c| c == '.' || c == '!' || c == '?' || c == '\n')
                    .unwrap_or(truncated_after.len());
                
                context.push_str(labels.12); // existing_content_after
                context.push_str("\n");
                // å®‰å…¨åœ°æˆªå–åˆ° end_pos
                let final_chars: Vec<char> = truncated_after.chars().collect();
                let final_text: String = final_chars[..end_pos.min(final_chars.len())].iter().collect();
                context.push_str(&final_text);
                context.push_str("\n");
                context.push_str(labels.13); // remaining_content_continues
                context.push_str("\n");
            } else {
                context.push_str(labels.12); // existing_content_after
                context.push_str("\n");
                context.push_str(&cleaned_after);
            }
        }
    }
    
    // ğŸ”¥ æ–°å¢ï¼šæ·»åŠ ç« ç¯€ç­†è¨˜åˆ°ä¸Šä¸‹æ–‡
    if let Some(notes) = chapter_notes {
        context.push_str("\n\nã€ç« ç¯€ç­†è¨˜ã€‘\n");
        context.push_str("ä½œè€…ç­†è¨˜ï¼š");
        context.push_str(&clean_text(&notes));
        context.push_str("\n");
        log::info!("âœ… ç« ç¯€ç­†è¨˜å·²æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ï¼Œé•·åº¦: {} å­—ç¬¦", notes.len());
    }
    
    // æ·»åŠ çºŒå¯«æŒ‡ç¤º
    context.push_str("\n\n");
    context.push_str(labels.14); // writing_instructions
    context.push_str("\n");
    
    // æ·»åŠ ç¹é«”ä¸­æ–‡çºŒå¯«è¦æ±‚ï¼ˆç°¡åŒ–ç‰ˆï¼‰
    context.push_str("é‡è¦ï¼šåœ¨æ¨™è¨˜çš„ä½ç½®æ’å…¥çºŒå¯«å…§å®¹ã€‚\n");
    context.push_str("ä¸è¦é‡è¤‡æˆ–é‡å¯«æ’å…¥é»å‰å¾Œçš„ç¾æœ‰å…§å®¹ã€‚\n");
    context.push_str("ä½ çš„å›æ‡‰æ‡‰è©²åªåŒ…å«è¦æ’å…¥çš„æ–°æ–‡æœ¬ã€‚\n\n");
    context.push_str("è¦æ±‚ï¼š\n");
    context.push_str("1. ä¿æŒè§’è‰²ä¸€è‡´æ€§å’Œå°è©±é¢¨æ ¼\n");
    context.push_str("2. å¾æ’å…¥é»å¹³æ»‘åœ°ç¹¼çºŒç•¶å‰æƒ…ç¯€ç™¼å±•\n");
    context.push_str("3. ä¿æŒç›¸åŒçš„å¯«ä½œé¢¨æ ¼å’Œæ•˜äº‹è¦–è§’\n");
    context.push_str("4. ç¢ºä¿ç´°ç¯€ä¸€è‡´æ€§ï¼ˆæ™‚é–“ã€åœ°é»ã€è§’è‰²ç‹€æ…‹ï¼‰\n");
    context.push_str("5. åªå¯«çºŒå¯«æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•å…ƒè©•è«–æˆ–è§£é‡‹\n");
    context.push_str("6. ç¢ºä¿ä½ çš„çºŒå¯«èˆ‡æ’å…¥é»å‰å¾Œçš„æ–‡æœ¬è‡ªç„¶éŠœæ¥\n");
    context.push_str("7. CRITICAL: åš´æ ¼ä½¿ç”¨ç¹é«”ä¸­æ–‡å¯«ä½œï¼Œçµ•å°ä¸å…è¨±æ··é›œä»»ä½•è‹±æ–‡å–®è©æˆ–ç°¡é«”å­—\n");
    
    // å¦‚æœæ˜¯è¼•å°èªªé¡å‹ï¼Œæ·»åŠ ç‰¹å®šæç¤ºï¼ˆç°¡åŒ–ç‰ˆï¼‰
    if let Some(project_type) = &project.r#type {
        let is_light_novel = project_type.to_lowercase().contains("è¼•å°èªª") || 
                           project_type.to_lowercase().contains("è½»å°è¯´") ||
                           project_type.to_lowercase().contains("light novel");
        
        if is_light_novel {
            context.push_str("\nè¼•å°èªªé¢¨æ ¼æç¤ºï¼š\n");
            context.push_str("- é©ç•¶åŠ å…¥è§’è‰²å…§å¿ƒç¨ç™½\n");
            context.push_str("- ä¿æŒç¯€å¥æ˜å¿«ï¼Œå°è©±ç”Ÿå‹•\n");
            context.push_str("- å¯ä»¥é©ç•¶ä½¿ç”¨æ“¬è²è©å’Œè¡¨æƒ…æå¯«\n");
        }
    }
    
    Ok(context)
}

/// å£“ç¸®ä¸Šä¸‹æ–‡ä»¥é©æ‡‰ token é™åˆ¶
#[command]
pub async fn compress_context(
    context: String,
    max_tokens: usize,
) -> Result<String, String> {
    // ç°¡å–®çš„å£“ç¸®ç­–ç•¥ï¼šä¼°ç®— token æ•¸ä¸¦æˆªæ–·
    // ä¸­æ–‡å¤§ç´„ 1.5-2 å­—ç¬¦ = 1 token
    let estimated_tokens = context.chars().count() / 2;
    
    if estimated_tokens <= max_tokens {
        return Ok(context);
    }
    
    // éœ€è¦å£“ç¸®ï¼Œå„ªå…ˆä¿ç•™ï¼š
    // 1. çºŒå¯«è¦æ±‚ï¼ˆæœ€å¾Œéƒ¨åˆ†ï¼‰
    // 2. ç•¶å‰ç« ç¯€å…§å®¹ï¼ˆç›¡å¯èƒ½å¤šï¼‰
    // 3. è§’è‰²è¨­å®šï¼ˆé‡è¦ï¼‰
    // 4. æ•…äº‹èƒŒæ™¯ï¼ˆæ¬¡è¦ï¼‰
    
    let sections: Vec<&str> = context.split("ã€").collect();
    let mut compressed = String::new();
    
    // ä¿ç•™çºŒå¯«è¦æ±‚
    if let Some(requirements) = sections.iter().find(|s| s.starts_with("çºŒå¯«è¦æ±‚ã€‘")) {
        compressed = format!("ã€{}\n\n", requirements);
    }
    
    // è¨ˆç®—å‰©é¤˜å¯ç”¨ token
    let requirements_tokens = compressed.chars().count() / 2;
    let remaining_tokens = max_tokens.saturating_sub(requirements_tokens);
    
    // å„ªå…ˆæ·»åŠ ç•¶å‰ç« ç¯€å…§å®¹
    if let Some(chapter) = sections.iter().find(|s| s.starts_with("ç•¶å‰ç« ç¯€ã€‘")) {
        let chapter_content = format!("ã€{}", chapter);
        let chapter_tokens = chapter_content.chars().count() / 2;
        
        if chapter_tokens <= remaining_tokens {
            compressed = format!("{}ã€{}\n\n", chapter_content, compressed);
        } else {
            // æˆªæ–·ç« ç¯€å…§å®¹
            let max_chars = remaining_tokens * 2;
            let truncated = chapter_content.chars().take(max_chars).collect::<String>();
            compressed = format!("{}\n...(å…§å®¹å·²æˆªæ–·)...\n\n{}", truncated, compressed);
        }
    }
    
    Ok(compressed)
}

/// ç²å–ä¸Šä¸‹æ–‡çµ±è¨ˆä¿¡æ¯
#[command]
pub async fn get_context_stats(project_id: String) -> Result<ContextStats, String> {
    let db = get_db().map_err(|e| e.to_string())?;
    
    // æ›´å¥½åœ°è™•ç† poisoned lock éŒ¯èª¤
    let conn = match db.lock() {
        Ok(conn) => conn,
        Err(poisoned) => {
            log::error!("è³‡æ–™åº«é–è¢« poisonedï¼Œå˜—è©¦æ¢å¾©: {}", poisoned);
            // å˜—è©¦æ¢å¾© poisoned lock
            poisoned.into_inner()
        }
    };
    
    // çµ±è¨ˆç« ç¯€æ•¸é‡
    let chapter_count: usize = conn
        .query_row(
            "SELECT COUNT(*) FROM chapters WHERE project_id = ?",
            [&project_id],
            |row| row.get(0)
        )
        .map_err(|e| e.to_string())?;
    
    // çµ±è¨ˆè§’è‰²æ•¸é‡
    let character_count: usize = conn
        .query_row(
            "SELECT COUNT(*) FROM characters WHERE project_id = ?",
            [&project_id],
            |row| row.get(0)
        )
        .map_err(|e| e.to_string())?;
    
    // çµ±è¨ˆç¸½å­—æ•¸
    let total_chars: usize = conn
        .query_row(
            "SELECT COALESCE(SUM(LENGTH(content)), 0) FROM chapters WHERE project_id = ?",
            [&project_id],
            |row| row.get(0)
        )
        .map_err(|e| e.to_string())?;
    
    // ä¼°ç®— token æ•¸ï¼ˆä¸­æ–‡ç´„ 1.5-2 å­—ç¬¦ = 1 tokenï¼‰
    let estimated_tokens = total_chars / 2;
    
    Ok(ContextStats {
        total_characters: total_chars,
        estimated_tokens,
        chapter_count,
        character_count,
    })
}

/// æ§‹å»ºåˆ†é›¢çš„ä¸Šä¸‹æ–‡ï¼ˆç³»çµ±æç¤º + ç”¨æˆ¶ä¸Šä¸‹æ–‡ï¼‰- ç°¡åŒ–ç‰ˆ
#[command]
pub async fn build_separated_context(
    project_id: String,
    chapter_id: String,
    position: usize,
) -> Result<(String, String), String> {
    log::info!("æ§‹å»ºåˆ†é›¢ä¸Šä¸‹æ–‡ - å°ˆæ¡ˆ: {}, ç« ç¯€: {}, ä½ç½®: {}", project_id, chapter_id, position);
    
    let db = get_db().map_err(|e| e.to_string())?;
    
    // è™•ç† poisoned lock éŒ¯èª¤
    let conn = match db.lock() {
        Ok(conn) => conn,
        Err(poisoned) => {
            log::error!("è³‡æ–™åº«é–è¢« poisonedï¼Œå˜—è©¦æ¢å¾©: {}", poisoned);
            poisoned.into_inner()
        }
    };
    
    // 1. ç²å–å°ˆæ¡ˆè³‡è¨Š
    let project: Project = conn
        .query_row(
            "SELECT id, name, description, type, novel_length, settings, created_at, updated_at FROM projects WHERE id = ?",
            [&project_id],
            |row| Ok(Project {
                id: row.get(0)?,
                name: row.get(1)?,
                description: row.get(2)?,
                r#type: row.get(3)?,
                novel_length: row.get(4)?,
                settings: row.get(5)?,
                created_at: row.get(6)?,
                updated_at: row.get(7)?,
            })
        )
        .map_err(|e| format!("ç²å–å°ˆæ¡ˆå¤±æ•—: {}", e))?;
    
    // 2. ç²å–ç•¶å‰ç« ç¯€å…§å®¹
    let chapter: Chapter = conn
        .query_row(
            "SELECT id, project_id, title, content, order_index, chapter_number, metadata, created_at, updated_at FROM chapters WHERE id = ?",
            [&chapter_id],
            |row| Ok(Chapter {
                id: row.get(0)?,
                project_id: row.get(1)?,
                title: row.get(2)?,
                content: row.get(3)?,
                order_index: row.get(4)?,
                chapter_number: row.get(5)?,
                metadata: row.get(6)?,
                created_at: row.get(7)?,
                updated_at: row.get(8)?,
            })
        )
        .map_err(|e| format!("ç²å–ç« ç¯€å¤±æ•—: {}", e))?;
    
    // 3. ç²å–å°ˆæ¡ˆçš„æ‰€æœ‰è§’è‰²
    let mut stmt = conn
        .prepare("SELECT id, project_id, name, description, attributes, avatar_url, created_at, updated_at FROM characters WHERE project_id = ?")
        .map_err(|e| e.to_string())?;
    
    let characters: Vec<Character> = stmt
        .query_map([&project_id], |row| {
            Ok(Character {
                id: row.get(0)?,
                project_id: row.get(1)?,
                name: row.get(2)?,
                description: row.get(3)?,
                attributes: row.get(4)?,
                avatar_url: row.get(5)?,
                created_at: row.get(6)?,
                updated_at: row.get(7)?,
            })
        })
        .map_err(|e| e.to_string())?
        .collect::<SqliteResult<Vec<_>>>()
        .map_err(|e| e.to_string())?;
    
    // 4. æ§‹å»ºç³»çµ±æç¤º
    let system_prompt_builder = SystemPromptBuilder::new(project.r#type.clone());
    let system_prompt = system_prompt_builder.build_system_prompt();
    
    // 5. æ§‹å»ºç”¨æˆ¶ä¸Šä¸‹æ–‡
    let user_context_builder = UserContextBuilder::new(project, chapter, characters, position);
    let user_context = user_context_builder.build_user_context();
    
    log::info!("ä¸Šä¸‹æ–‡æ§‹å»ºå®Œæˆ - ç³»çµ±æç¤º: {} å­—ç¬¦, ç”¨æˆ¶ä¸Šä¸‹æ–‡: {} å­—ç¬¦", 
              system_prompt.chars().count(), 
              user_context.chars().count());
    
    Ok((system_prompt, user_context))
}

/// ä¼°ç®—åˆ†é›¢ä¸Šä¸‹æ–‡çš„ token ä½¿ç”¨æƒ…æ³
#[command]
pub async fn estimate_separated_context_tokens(project_id: String) -> Result<SeparatedContextStats, String> {
    let db = get_db().map_err(|e| e.to_string())?;
    
    let conn = match db.lock() {
        Ok(conn) => conn,
        Err(poisoned) => {
            log::error!("è³‡æ–™åº«é–è¢« poisonedï¼Œå˜—è©¦æ¢å¾©: {}", poisoned);
            poisoned.into_inner()
        }
    };
    
    // ç²å–å°ˆæ¡ˆé¡å‹ç”¨æ–¼ç³»çµ±æç¤ºä¼°ç®—
    let project_type: Option<String> = conn
        .query_row(
            "SELECT type FROM projects WHERE id = ?",
            [&project_id],
            |row| Ok(row.get(0)?)
        )
        .map_err(|e| format!("ç²å–å°ˆæ¡ˆé¡å‹å¤±æ•—: {}", e))?;
    
    // çµ±è¨ˆç”¨æˆ¶å…§å®¹ï¼ˆç”¨æ–¼æ—¥èªŒè¨˜éŒ„ï¼‰
    let _total_chars: usize = conn
        .query_row(
            "SELECT COALESCE(SUM(LENGTH(content)), 0) FROM chapters WHERE project_id = ?",
            [&project_id],
            |row| row.get(0)
        )
        .map_err(|e| e.to_string())?;
    
    let character_count: usize = conn
        .query_row(
            "SELECT COUNT(*) FROM characters WHERE project_id = ?",
            [&project_id],
            |row| row.get(0)
        )
        .map_err(|e| e.to_string())?;
    
    // ä¼°ç®—ç³»çµ±æç¤º tokenï¼ˆç›¸å°å›ºå®šï¼‰
    let system_prompt_builder = SystemPromptBuilder::new(project_type);
    let system_prompt = system_prompt_builder.build_system_prompt();
    let system_prompt_tokens = system_prompt.chars().count() / 2; // ä¸­æ–‡ç´„ 2 å­—ç¬¦ = 1 token
    
    // ä¼°ç®—ç”¨æˆ¶ä¸Šä¸‹æ–‡ tokenï¼ˆå‹•æ…‹ï¼‰
    let estimated_user_context_chars = 200 + // é …ç›®ä¿¡æ¯
        (character_count * 100) + // è§’è‰²ä¿¡æ¯ï¼ˆç°¡åŒ–ï¼‰
        1000; // ç« ç¯€å…§å®¹ï¼ˆæˆªæ–·å¾Œï¼‰
    let user_context_tokens = estimated_user_context_chars / 2;
    
    let total_tokens = system_prompt_tokens + user_context_tokens;
    let efficiency = (user_context_tokens as f32 / total_tokens as f32) * 100.0;
    
    Ok(SeparatedContextStats {
        system_prompt_tokens,
        user_context_tokens,
        total_tokens,
        efficiency_percentage: efficiency,
        character_count,
        estimated_savings_vs_legacy: 40.0, // é ä¼°ç¯€çœ 40%
    })
}

/// æª¢æ¸¬æ–‡æœ¬çš„èªè¨€ç´”åº¦
#[command]
pub async fn analyze_text_purity(text: String) -> Result<PurityAnalysisResult, String> {
    let enforcer = LanguagePurityEnforcer::new();
    let analysis = enforcer.analyze_purity(&text);
    
    Ok(PurityAnalysisResult {
        is_pure: analysis.is_pure,
        purity_score: analysis.purity_score,
        issues: analysis.issues.into_iter().map(|issue| PurityIssueResult {
            issue_type: match issue.issue_type {
                crate::utils::language_purity::IssueType::EnglishWords => "english_words".to_string(),
                crate::utils::language_purity::IssueType::SimplifiedChinese => "simplified_chinese".to_string(),
                crate::utils::language_purity::IssueType::ForbiddenPattern => "forbidden_pattern".to_string(),
            },
            content: issue.content,
            severity: match issue.severity {
                crate::utils::language_purity::Severity::High => "high".to_string(),
                crate::utils::language_purity::Severity::Medium => "medium".to_string(),
                crate::utils::language_purity::Severity::Low => "low".to_string(),
            },
        }).collect(),
    })
}

/// ç”Ÿæˆå¢å¼·çš„ AI ç”Ÿæˆåƒæ•¸
#[command]
pub async fn enhance_generation_parameters(
    base_parameters: serde_json::Value
) -> Result<serde_json::Value, String> {
    let enforcer = LanguagePurityEnforcer::new();
    
    if let Some(params_obj) = base_parameters.as_object() {
        let enhanced = enforcer.enhance_generation_options(params_obj.clone());
        Ok(serde_json::Value::Object(enhanced))
    } else {
        Err("åƒæ•¸å¿…é ˆæ˜¯ JSON ç‰©ä»¶".to_string())
    }
}

#[derive(Debug, Serialize, Deserialize)]
pub struct PurityAnalysisResult {
    pub is_pure: bool,
    pub purity_score: f64,
    pub issues: Vec<PurityIssueResult>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct PurityIssueResult {
    pub issue_type: String,
    pub content: String,
    pub severity: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct SeparatedContextStats {
    pub system_prompt_tokens: usize,
    pub user_context_tokens: usize,
    pub total_tokens: usize,
    pub efficiency_percentage: f32,
    pub character_count: usize,
    pub estimated_savings_vs_legacy: f32,
}